{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingfeng/Desktop/venvs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Literal\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "from utils.loader import MovieLensDataset\n",
    "from arquitecture.Recommender import Recommender_2\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 55\n",
    "BATCH = 800\n",
    "NUN_THREADS = 6\n",
    "DEVICE = \"cuda\"\n",
    "NUM_EPOCH = 100\n",
    "LEARNING_RATE = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Tensor Shape: torch.Size([678, 22, 19])\n",
      "User Data Tensor Shape: torch.Size([678, 23])\n",
      "Max index in rating tensor: 100\n",
      "Min index in rating tensor: 0\n",
      "Actual num_ratings from tensor: 22\n",
      "Actual user_data_input_dim: 23\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"train\", transpose_ratings=True, seed=SEED)\n",
    "test_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"test\", transpose_ratings=True, seed=SEED)\n",
    "val_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"val\", transpose_ratings=True, seed=SEED)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "\n",
    "for user_data_tensor, rating_train_tensor, rating_test_tensor in train_dataloader:\n",
    "    print(\"Rating Tensor Shape:\", rating_train_tensor.size())\n",
    "    print(\"User Data Tensor Shape:\", user_data_tensor.size())\n",
    "    print(f\"Max index in rating tensor: {rating_train_tensor.max().item()}\")\n",
    "    print(f\"Min index in rating tensor: {rating_train_tensor.min().item()}\")\n",
    "    \n",
    "    # Get true num_ratings from data\n",
    "    batch_size, num_ratings_actual, rating_size = rating_train_tensor.size()\n",
    "    user_batch_size, user_data_dim = user_data_tensor.size()\n",
    "    \n",
    "    print(f\"Actual num_ratings from tensor: {num_ratings_actual}\")\n",
    "    print(f\"Actual user_data_input_dim: {user_data_dim}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    ratings_embedding_dim = trial.suggest_int('ratings_embedding_dim', 4, 24)\n",
    "    ratings_lstm_hidden_size = trial.suggest_int('ratings_lstm_hidden_size', 8, 16)\n",
    "    ratings_lstm_num_layers = trial.suggest_int('ratings_lstm_num_layers', 1, 16)\n",
    "    ratings_word_size = trial.suggest_int('ratings_word_size', 8, 16)\n",
    "    ratings_final_mlp_factor = trial.suggest_int('ratings_final_mlp_factor', 2, 16)\n",
    "    ratings_embedding_output = trial.suggest_int('ratings_embedding_output', 4, 24)\n",
    "    \n",
    "    user_embedding_dim = trial.suggest_int('user_embedding_dim', 8, 16)\n",
    "    user_embedding_output = trial.suggest_int('user_embedding_output', 8, 16)\n",
    "    user_factor = trial.suggest_int('user_factor', 2, 16)\n",
    "    \n",
    "    final_output_size = 19  # Fixed, since this depends on your target size\n",
    "    expert_factor = trial.suggest_int('expert_factor', 2, 16)\n",
    "    \n",
    "    # Create model with suggested hyperparameters\n",
    "    max_index_in_data = rating_train_tensor.max().item()\n",
    "    ratings_num_embeddings = max_index_in_data + 1  # Add 1 since indices are 0-based\n",
    "    \n",
    "    model = Recommender_2(\n",
    "        # For ratings embedder\n",
    "        ratings_num_embeddings=ratings_num_embeddings,\n",
    "        ratings_embedding_dim=ratings_embedding_dim,\n",
    "        ratings_num_ratings=num_ratings_actual,\n",
    "        ratings_lstm_hidden_size=ratings_lstm_hidden_size,\n",
    "        ratings_lstm_num_layers=ratings_lstm_num_layers,\n",
    "        ratings_word_size=ratings_word_size,\n",
    "        ratings_final_mlp_factor=ratings_final_mlp_factor,\n",
    "        ratings_embedding_output=ratings_embedding_output,\n",
    "        # For user embedder\n",
    "        user_num_embeddings=100,  # Could be optimized too if variable\n",
    "        user_embedding_dim=user_embedding_dim,\n",
    "        user_embedding_output=user_embedding_output,\n",
    "        user_data_input_dim=user_data_dim,\n",
    "        user_factor=user_factor,\n",
    "        # Output layer\n",
    "        final_output_size=final_output_size,\n",
    "        expert_factor=expert_factor\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    # Create model with hyperparameters suggested by Optuna\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Print model parameters for reference\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trial {trial.number} - Model parameters: {num_params}\")\n",
    "    \n",
    "    # Train and evaluate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # Track best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for user_data_tensor, rating_train_tensor, rating_test_tensor in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE)).to(DEVICE)\n",
    "            loss = criterion(outputs.to(DEVICE), rating_test_tensor.to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader.dataset)\n",
    "        \n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for user_data_tensor, rating_train_tensor, rating_test_tensor in val_dataloader:\n",
    "                outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE))\n",
    "                loss = criterion(outputs, rating_test_tensor.to(DEVICE))\n",
    "                running_val_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "        \n",
    "        print(f\"Trial {trial.number}, Epoch [{epoch+1}/{NUM_EPOCH}] - \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "        \n",
    "        # Report intermediate values to Optuna\n",
    "        trial.report(epoch_val_loss, epoch)\n",
    "        \n",
    "        # Handle pruning (early stopping if this trial isn't promising)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "def evaluate(model: Recommender_2):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        for user_data_tensor, rating_train_tensor, rating_test_tensor, _ in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE)).to(DEVICE)        \n",
    "            loss = criterion(outputs.to(DEVICE), rating_test_tensor.to(DEVICE)) \n",
    "            \n",
    "            loss.backward()                 # Backpropagation\n",
    "            optimizer.step()                # Update model parameters\n",
    "            running_train_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader.dataset)\n",
    "\n",
    "        # --- Validation Phase ---32\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for user_data_tensor, rating_train_tensor, rating_test_tensor, _ in val_dataloader:\n",
    "                \n",
    "                outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE))        \n",
    "                loss = criterion(outputs, rating_test_tensor.to(DEVICE)) \n",
    "                \n",
    "                running_val_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCH}] - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    \n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(n_trials=50):\n",
    "    study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=1)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    \n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    # Create the best model\n",
    "    best_model = create_model(trial)\n",
    "    \n",
    "    return best_model, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 18:47:33,527] A new study created in memory with name: no-name-5c4d5d74-0ec7-4f7f-b772-893c90a10132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 - Model parameters: 1522929\n",
      "Trial 0, Epoch [1/100] - Train Loss: 41.7501, Val Loss: 42.5169\n",
      "Trial 0, Epoch [2/100] - Train Loss: 41.6412, Val Loss: 42.4149\n",
      "Trial 0, Epoch [3/100] - Train Loss: 41.5361, Val Loss: 42.3145\n",
      "Trial 0, Epoch [4/100] - Train Loss: 41.4314, Val Loss: 42.2101\n",
      "Trial 0, Epoch [5/100] - Train Loss: 41.3215, Val Loss: 42.1001\n",
      "Trial 0, Epoch [6/100] - Train Loss: 41.2047, Val Loss: 41.9816\n",
      "Trial 0, Epoch [7/100] - Train Loss: 41.0779, Val Loss: 41.8423\n",
      "Trial 0, Epoch [8/100] - Train Loss: 40.9272, Val Loss: 41.6712\n",
      "Trial 0, Epoch [9/100] - Train Loss: 40.7403, Val Loss: 41.4854\n",
      "Trial 0, Epoch [10/100] - Train Loss: 40.5347, Val Loss: 41.2294\n",
      "Trial 0, Epoch [11/100] - Train Loss: 40.2488, Val Loss: 40.9106\n",
      "Trial 0, Epoch [12/100] - Train Loss: 39.8925, Val Loss: 40.4905\n",
      "Trial 0, Epoch [13/100] - Train Loss: 39.4280, Val Loss: 40.1204\n",
      "Trial 0, Epoch [14/100] - Train Loss: 39.0014, Val Loss: 39.5605\n",
      "Trial 0, Epoch [15/100] - Train Loss: 38.3350, Val Loss: 38.9332\n",
      "Trial 0, Epoch [16/100] - Train Loss: 37.5443, Val Loss: 38.6723\n",
      "Trial 0, Epoch [17/100] - Train Loss: 37.0743, Val Loss: 38.5964\n",
      "Trial 0, Epoch [18/100] - Train Loss: 36.8581, Val Loss: 37.9760\n",
      "Trial 0, Epoch [19/100] - Train Loss: 36.2515, Val Loss: 37.2996\n",
      "Trial 0, Epoch [20/100] - Train Loss: 35.6724, Val Loss: 36.8717\n",
      "Trial 0, Epoch [21/100] - Train Loss: 35.3519, Val Loss: 36.7030\n",
      "Trial 0, Epoch [22/100] - Train Loss: 35.2645, Val Loss: 36.6547\n",
      "Trial 0, Epoch [23/100] - Train Loss: 35.2531, Val Loss: 36.5573\n",
      "Trial 0, Epoch [24/100] - Train Loss: 35.1525, Val Loss: 36.4543\n",
      "Trial 0, Epoch [25/100] - Train Loss: 35.0162, Val Loss: 36.4163\n",
      "Trial 0, Epoch [26/100] - Train Loss: 34.9274, Val Loss: 36.4104\n",
      "Trial 0, Epoch [27/100] - Train Loss: 34.8716, Val Loss: 36.3287\n",
      "Trial 0, Epoch [28/100] - Train Loss: 34.7648, Val Loss: 36.1658\n",
      "Trial 0, Epoch [29/100] - Train Loss: 34.6038, Val Loss: 36.0219\n",
      "Trial 0, Epoch [30/100] - Train Loss: 34.4790, Val Loss: 35.9425\n",
      "Trial 0, Epoch [31/100] - Train Loss: 34.4164, Val Loss: 35.8983\n",
      "Trial 0, Epoch [32/100] - Train Loss: 34.3747, Val Loss: 35.8489\n",
      "Trial 0, Epoch [33/100] - Train Loss: 34.3098, Val Loss: 35.7969\n",
      "Trial 0, Epoch [34/100] - Train Loss: 34.2264, Val Loss: 35.7461\n",
      "Trial 0, Epoch [35/100] - Train Loss: 34.1439, Val Loss: 35.6899\n",
      "Trial 0, Epoch [36/100] - Train Loss: 34.0699, Val Loss: 35.5938\n",
      "Trial 0, Epoch [37/100] - Train Loss: 33.9819, Val Loss: 35.4675\n",
      "Trial 0, Epoch [38/100] - Train Loss: 33.8847, Val Loss: 35.3438\n",
      "Trial 0, Epoch [39/100] - Train Loss: 33.7984, Val Loss: 35.2367\n",
      "Trial 0, Epoch [40/100] - Train Loss: 33.7231, Val Loss: 35.1283\n",
      "Trial 0, Epoch [41/100] - Train Loss: 33.6327, Val Loss: 34.9993\n",
      "Trial 0, Epoch [42/100] - Train Loss: 33.5085, Val Loss: 34.8421\n",
      "Trial 0, Epoch [43/100] - Train Loss: 33.3457, Val Loss: 34.6657\n",
      "Trial 0, Epoch [44/100] - Train Loss: 33.1598, Val Loss: 34.4200\n",
      "Trial 0, Epoch [45/100] - Train Loss: 32.9319, Val Loss: 34.1064\n",
      "Trial 0, Epoch [46/100] - Train Loss: 32.6526, Val Loss: 33.7469\n",
      "Trial 0, Epoch [47/100] - Train Loss: 32.3445, Val Loss: 33.3850\n",
      "Trial 0, Epoch [48/100] - Train Loss: 32.0020, Val Loss: 33.0907\n",
      "Trial 0, Epoch [49/100] - Train Loss: 31.7292, Val Loss: 32.9354\n",
      "Trial 0, Epoch [50/100] - Train Loss: 31.6103, Val Loss: 32.9181\n",
      "Trial 0, Epoch [51/100] - Train Loss: 31.6209, Val Loss: 32.7373\n",
      "Trial 0, Epoch [52/100] - Train Loss: 31.5566, Val Loss: 32.6931\n",
      "Trial 0, Epoch [53/100] - Train Loss: 31.5138, Val Loss: 32.4196\n",
      "Trial 0, Epoch [54/100] - Train Loss: 31.3261, Val Loss: 32.4365\n",
      "Trial 0, Epoch [55/100] - Train Loss: 31.4062, Val Loss: 32.3527\n",
      "Trial 0, Epoch [56/100] - Train Loss: 31.2775, Val Loss: 32.3806\n",
      "Trial 0, Epoch [57/100] - Train Loss: 31.2723, Val Loss: 32.3216\n",
      "Trial 0, Epoch [58/100] - Train Loss: 31.1985, Val Loss: 32.2592\n",
      "Trial 0, Epoch [59/100] - Train Loss: 31.1367, Val Loss: 32.2694\n",
      "Trial 0, Epoch [60/100] - Train Loss: 31.1473, Val Loss: 32.2750\n",
      "Trial 0, Epoch [61/100] - Train Loss: 31.1305, Val Loss: 32.3239\n",
      "Trial 0, Epoch [62/100] - Train Loss: 31.1496, Val Loss: 32.3749\n",
      "Trial 0, Epoch [63/100] - Train Loss: 31.1860, Val Loss: 32.3448\n",
      "Trial 0, Epoch [64/100] - Train Loss: 31.1695, Val Loss: 32.3135\n",
      "Trial 0, Epoch [65/100] - Train Loss: 31.1623, Val Loss: 32.2923\n",
      "Trial 0, Epoch [66/100] - Train Loss: 31.1526, Val Loss: 32.2665\n",
      "Trial 0, Epoch [67/100] - Train Loss: 31.1229, Val Loss: 32.2709\n",
      "Trial 0, Epoch [68/100] - Train Loss: 31.1176, Val Loss: 32.2758\n",
      "Trial 0, Epoch [69/100] - Train Loss: 31.1230, Val Loss: 32.2519\n",
      "Trial 0, Epoch [70/100] - Train Loss: 31.1133, Val Loss: 32.2284\n",
      "Trial 0, Epoch [71/100] - Train Loss: 31.1079, Val Loss: 32.2170\n",
      "Trial 0, Epoch [72/100] - Train Loss: 31.1064, Val Loss: 32.2073\n",
      "Trial 0, Epoch [73/100] - Train Loss: 31.0919, Val Loss: 32.2081\n",
      "Trial 0, Epoch [74/100] - Train Loss: 31.0798, Val Loss: 32.2153\n",
      "Trial 0, Epoch [75/100] - Train Loss: 31.0807, Val Loss: 32.2083\n",
      "Trial 0, Epoch [76/100] - Train Loss: 31.0760, Val Loss: 32.1906\n",
      "Trial 0, Epoch [77/100] - Train Loss: 31.0678, Val Loss: 32.1802\n",
      "Trial 0, Epoch [78/100] - Train Loss: 31.0658, Val Loss: 32.1753\n",
      "Trial 0, Epoch [79/100] - Train Loss: 31.0612, Val Loss: 32.1753\n",
      "Trial 0, Epoch [80/100] - Train Loss: 31.0523, Val Loss: 32.1842\n",
      "Trial 0, Epoch [81/100] - Train Loss: 31.0484, Val Loss: 32.1922\n",
      "Trial 0, Epoch [82/100] - Train Loss: 31.0450, Val Loss: 32.1914\n",
      "Trial 0, Epoch [83/100] - Train Loss: 31.0371, Val Loss: 32.1922\n",
      "Trial 0, Epoch [84/100] - Train Loss: 31.0325, Val Loss: 32.1990\n",
      "Trial 0, Epoch [85/100] - Train Loss: 31.0322, Val Loss: 32.2075\n",
      "Trial 0, Epoch [86/100] - Train Loss: 31.0300, Val Loss: 32.2162\n",
      "Trial 0, Epoch [87/100] - Train Loss: 31.0274, Val Loss: 32.2212\n",
      "Trial 0, Epoch [88/100] - Train Loss: 31.0259, Val Loss: 32.2160\n",
      "Trial 0, Epoch [89/100] - Train Loss: 31.0220, Val Loss: 32.2043\n",
      "Trial 0, Epoch [90/100] - Train Loss: 31.0177, Val Loss: 32.1960\n",
      "Trial 0, Epoch [91/100] - Train Loss: 31.0168, Val Loss: 32.1932\n",
      "Trial 0, Epoch [92/100] - Train Loss: 31.0161, Val Loss: 32.1945\n",
      "Trial 0, Epoch [93/100] - Train Loss: 31.0137, Val Loss: 32.1983\n",
      "Trial 0, Epoch [94/100] - Train Loss: 31.0117, Val Loss: 32.1995\n",
      "Trial 0, Epoch [95/100] - Train Loss: 31.0091, Val Loss: 32.1973\n",
      "Trial 0, Epoch [96/100] - Train Loss: 31.0055, Val Loss: 32.1958\n",
      "Trial 0, Epoch [97/100] - Train Loss: 31.0030, Val Loss: 32.1963\n",
      "Trial 0, Epoch [98/100] - Train Loss: 31.0009, Val Loss: 32.1973\n",
      "Trial 0, Epoch [99/100] - Train Loss: 30.9978, Val Loss: 32.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 18:55:55,224] Trial 0 finished with value: 32.175254821777344 and parameters: {'ratings_embedding_dim': 14, 'ratings_lstm_hidden_size': 11, 'ratings_lstm_num_layers': 15, 'ratings_word_size': 15, 'ratings_final_mlp_factor': 4, 'ratings_embedding_output': 9, 'user_embedding_dim': 14, 'user_embedding_output': 15, 'user_factor': 3, 'expert_factor': 11}. Best is trial 0 with value: 32.175254821777344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0, Epoch [100/100] - Train Loss: 30.9951, Val Loss: 32.1956\n",
      "Trial 1 - Model parameters: 1243613\n",
      "Trial 1, Epoch [1/100] - Train Loss: 35.2953, Val Loss: 35.2954\n",
      "Trial 1, Epoch [2/100] - Train Loss: 35.0507, Val Loss: 35.0553\n",
      "Trial 1, Epoch [3/100] - Train Loss: 34.8191, Val Loss: 34.8154\n",
      "Trial 1, Epoch [4/100] - Train Loss: 34.5881, Val Loss: 34.5766\n",
      "Trial 1, Epoch [5/100] - Train Loss: 34.3586, Val Loss: 34.3336\n",
      "Trial 1, Epoch [6/100] - Train Loss: 34.1258, Val Loss: 34.0855\n",
      "Trial 1, Epoch [7/100] - Train Loss: 33.8886, Val Loss: 33.8401\n",
      "Trial 1, Epoch [8/100] - Train Loss: 33.6544, Val Loss: 33.5955\n",
      "Trial 1, Epoch [9/100] - Train Loss: 33.4213, Val Loss: 33.3545\n",
      "Trial 1, Epoch [10/100] - Train Loss: 33.1913, Val Loss: 33.0948\n",
      "Trial 1, Epoch [11/100] - Train Loss: 32.9445, Val Loss: 32.8185\n",
      "Trial 1, Epoch [12/100] - Train Loss: 32.6836, Val Loss: 32.5401\n",
      "Trial 1, Epoch [13/100] - Train Loss: 32.4220, Val Loss: 32.2690\n",
      "Trial 1, Epoch [14/100] - Train Loss: 32.1672, Val Loss: 31.9613\n",
      "Trial 1, Epoch [15/100] - Train Loss: 31.8762, Val Loss: 31.6512\n",
      "Trial 1, Epoch [16/100] - Train Loss: 31.5800, Val Loss: 31.3685\n",
      "Trial 1, Epoch [17/100] - Train Loss: 31.3056, Val Loss: 31.0595\n",
      "Trial 1, Epoch [18/100] - Train Loss: 31.0066, Val Loss: 30.6572\n",
      "Trial 1, Epoch [19/100] - Train Loss: 30.6192, Val Loss: 30.2087\n",
      "Trial 1, Epoch [20/100] - Train Loss: 30.1876, Val Loss: 29.7869\n",
      "Trial 1, Epoch [21/100] - Train Loss: 29.7815, Val Loss: 29.2913\n",
      "Trial 1, Epoch [22/100] - Train Loss: 29.3125, Val Loss: 28.7762\n",
      "Trial 1, Epoch [23/100] - Train Loss: 28.8199, Val Loss: 28.2059\n",
      "Trial 1, Epoch [24/100] - Train Loss: 28.2757, Val Loss: 27.5935\n",
      "Trial 1, Epoch [25/100] - Train Loss: 27.6917, Val Loss: 26.9562\n",
      "Trial 1, Epoch [26/100] - Train Loss: 27.0990, Val Loss: 26.1599\n",
      "Trial 1, Epoch [27/100] - Train Loss: 26.3860, Val Loss: 25.4436\n",
      "Trial 1, Epoch [28/100] - Train Loss: 25.7682, Val Loss: 24.9957\n",
      "Trial 1, Epoch [29/100] - Train Loss: 25.4426, Val Loss: 24.7915\n",
      "Trial 1, Epoch [30/100] - Train Loss: 25.3607, Val Loss: 24.7316\n",
      "Trial 1, Epoch [31/100] - Train Loss: 25.4049, Val Loss: 24.5271\n",
      "Trial 1, Epoch [32/100] - Train Loss: 25.2231, Val Loss: 24.0767\n",
      "Trial 1, Epoch [33/100] - Train Loss: 24.7324, Val Loss: 23.7419\n",
      "Trial 1, Epoch [34/100] - Train Loss: 24.3252, Val Loss: 23.5857\n",
      "Trial 1, Epoch [35/100] - Train Loss: 24.0865, Val Loss: 23.5879\n",
      "Trial 1, Epoch [36/100] - Train Loss: 24.0062, Val Loss: 23.5771\n",
      "Trial 1, Epoch [37/100] - Train Loss: 23.9527, Val Loss: 23.4509\n",
      "Trial 1, Epoch [38/100] - Train Loss: 23.8153, Val Loss: 23.2095\n",
      "Trial 1, Epoch [39/100] - Train Loss: 23.5878, Val Loss: 22.9212\n",
      "Trial 1, Epoch [40/100] - Train Loss: 23.3342, Val Loss: 22.7308\n",
      "Trial 1, Epoch [41/100] - Train Loss: 23.1871, Val Loss: 22.6797\n",
      "Trial 1, Epoch [42/100] - Train Loss: 23.1772, Val Loss: 22.7006\n",
      "Trial 1, Epoch [43/100] - Train Loss: 23.2199, Val Loss: 22.6834\n",
      "Trial 1, Epoch [44/100] - Train Loss: 23.1929, Val Loss: 22.6169\n",
      "Trial 1, Epoch [45/100] - Train Loss: 23.0899, Val Loss: 22.5763\n",
      "Trial 1, Epoch [46/100] - Train Loss: 23.0016, Val Loss: 22.5986\n",
      "Trial 1, Epoch [47/100] - Train Loss: 22.9790, Val Loss: 22.6540\n",
      "Trial 1, Epoch [48/100] - Train Loss: 23.0013, Val Loss: 22.6905\n",
      "Trial 1, Epoch [49/100] - Train Loss: 23.0222, Val Loss: 22.6801\n",
      "Trial 1, Epoch [50/100] - Train Loss: 23.0133, Val Loss: 22.6277\n",
      "Trial 1, Epoch [51/100] - Train Loss: 22.9774, Val Loss: 22.5581\n",
      "Trial 1, Epoch [52/100] - Train Loss: 22.9362, Val Loss: 22.5055\n",
      "Trial 1, Epoch [53/100] - Train Loss: 22.9168, Val Loss: 22.4804\n",
      "Trial 1, Epoch [54/100] - Train Loss: 22.9228, Val Loss: 22.4697\n",
      "Trial 1, Epoch [55/100] - Train Loss: 22.9341, Val Loss: 22.4555\n",
      "Trial 1, Epoch [56/100] - Train Loss: 22.9291, Val Loss: 22.4373\n",
      "Trial 1, Epoch [57/100] - Train Loss: 22.9075, Val Loss: 22.4280\n",
      "Trial 1, Epoch [58/100] - Train Loss: 22.8869, Val Loss: 22.4343\n",
      "Trial 1, Epoch [59/100] - Train Loss: 22.8794, Val Loss: 22.4478\n",
      "Trial 1, Epoch [60/100] - Train Loss: 22.8814, Val Loss: 22.4547\n",
      "Trial 1, Epoch [61/100] - Train Loss: 22.8819, Val Loss: 22.4466\n",
      "Trial 1, Epoch [62/100] - Train Loss: 22.8739, Val Loss: 22.4255\n",
      "Trial 1, Epoch [63/100] - Train Loss: 22.8584, Val Loss: 22.4000\n",
      "Trial 1, Epoch [64/100] - Train Loss: 22.8423, Val Loss: 22.3782\n",
      "Trial 1, Epoch [65/100] - Train Loss: 22.8313, Val Loss: 22.3649\n",
      "Trial 1, Epoch [66/100] - Train Loss: 22.8269, Val Loss: 22.3581\n",
      "Trial 1, Epoch [67/100] - Train Loss: 22.8249, Val Loss: 22.3537\n",
      "Trial 1, Epoch [68/100] - Train Loss: 22.8191, Val Loss: 22.3501\n",
      "Trial 1, Epoch [69/100] - Train Loss: 22.8087, Val Loss: 22.3492\n",
      "Trial 1, Epoch [70/100] - Train Loss: 22.7977, Val Loss: 22.3521\n",
      "Trial 1, Epoch [71/100] - Train Loss: 22.7901, Val Loss: 22.3565\n",
      "Trial 1, Epoch [72/100] - Train Loss: 22.7857, Val Loss: 22.3576\n",
      "Trial 1, Epoch [73/100] - Train Loss: 22.7817, Val Loss: 22.3522\n",
      "Trial 1, Epoch [74/100] - Train Loss: 22.7755, Val Loss: 22.3406\n",
      "Trial 1, Epoch [75/100] - Train Loss: 22.7671, Val Loss: 22.3263\n",
      "Trial 1, Epoch [76/100] - Train Loss: 22.7585, Val Loss: 22.3128\n",
      "Trial 1, Epoch [77/100] - Train Loss: 22.7517, Val Loss: 22.3022\n",
      "Trial 1, Epoch [78/100] - Train Loss: 22.7466, Val Loss: 22.2941\n",
      "Trial 1, Epoch [79/100] - Train Loss: 22.7412, Val Loss: 22.2876\n",
      "Trial 1, Epoch [80/100] - Train Loss: 22.7342, Val Loss: 22.2829\n",
      "Trial 1, Epoch [81/100] - Train Loss: 22.7261, Val Loss: 22.2802\n",
      "Trial 1, Epoch [82/100] - Train Loss: 22.7186, Val Loss: 22.2784\n",
      "Trial 1, Epoch [83/100] - Train Loss: 22.7127, Val Loss: 22.2755\n",
      "Trial 1, Epoch [84/100] - Train Loss: 22.7072, Val Loss: 22.2699\n",
      "Trial 1, Epoch [85/100] - Train Loss: 22.7012, Val Loss: 22.2614\n",
      "Trial 1, Epoch [86/100] - Train Loss: 22.6942, Val Loss: 22.2513\n",
      "Trial 1, Epoch [87/100] - Train Loss: 22.6871, Val Loss: 22.2411\n",
      "Trial 1, Epoch [88/100] - Train Loss: 22.6806, Val Loss: 22.2323\n",
      "Trial 1, Epoch [89/100] - Train Loss: 22.6749, Val Loss: 22.2253\n",
      "Trial 1, Epoch [90/100] - Train Loss: 22.6691, Val Loss: 22.2197\n",
      "Trial 1, Epoch [91/100] - Train Loss: 22.6625, Val Loss: 22.2156\n",
      "Trial 1, Epoch [92/100] - Train Loss: 22.6557, Val Loss: 22.2127\n",
      "Trial 1, Epoch [93/100] - Train Loss: 22.6491, Val Loss: 22.2101\n",
      "Trial 1, Epoch [94/100] - Train Loss: 22.6430, Val Loss: 22.2065\n",
      "Trial 1, Epoch [95/100] - Train Loss: 22.6369, Val Loss: 22.2011\n",
      "Trial 1, Epoch [96/100] - Train Loss: 22.6305, Val Loss: 22.1944\n",
      "Trial 1, Epoch [97/100] - Train Loss: 22.6239, Val Loss: 22.1875\n",
      "Trial 1, Epoch [98/100] - Train Loss: 22.6174, Val Loss: 22.1813\n",
      "Trial 1, Epoch [99/100] - Train Loss: 22.6113, Val Loss: 22.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:04:11,919] Trial 1 finished with value: 22.17156410217285 and parameters: {'ratings_embedding_dim': 9, 'ratings_lstm_hidden_size': 16, 'ratings_lstm_num_layers': 12, 'ratings_word_size': 12, 'ratings_final_mlp_factor': 5, 'ratings_embedding_output': 15, 'user_embedding_dim': 11, 'user_embedding_output': 8, 'user_factor': 3, 'expert_factor': 8}. Best is trial 1 with value: 22.17156410217285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Epoch [100/100] - Train Loss: 22.6051, Val Loss: 22.1716\n",
      "Trial 2 - Model parameters: 983772\n",
      "Trial 2, Epoch [1/100] - Train Loss: 58.3748, Val Loss: 58.2744\n",
      "Trial 2, Epoch [2/100] - Train Loss: 58.2340, Val Loss: 58.1366\n",
      "Trial 2, Epoch [3/100] - Train Loss: 58.1005, Val Loss: 57.9976\n",
      "Trial 2, Epoch [4/100] - Train Loss: 57.9656, Val Loss: 57.8567\n",
      "Trial 2, Epoch [5/100] - Train Loss: 57.8289, Val Loss: 57.7112\n",
      "Trial 2, Epoch [6/100] - Train Loss: 57.6876, Val Loss: 57.5587\n",
      "Trial 2, Epoch [7/100] - Train Loss: 57.5393, Val Loss: 57.3979\n",
      "Trial 2, Epoch [8/100] - Train Loss: 57.3828, Val Loss: 57.2325\n",
      "Trial 2, Epoch [9/100] - Train Loss: 57.2217, Val Loss: 57.0750\n",
      "Trial 2, Epoch [10/100] - Train Loss: 57.0650, Val Loss: 56.9026\n",
      "Trial 2, Epoch [11/100] - Train Loss: 56.8963, Val Loss: 56.6842\n",
      "Trial 2, Epoch [12/100] - Train Loss: 56.6854, Val Loss: 56.4491\n",
      "Trial 2, Epoch [13/100] - Train Loss: 56.4580, Val Loss: 56.2639\n",
      "Trial 2, Epoch [14/100] - Train Loss: 56.2801, Val Loss: 56.0899\n",
      "Trial 2, Epoch [15/100] - Train Loss: 56.1118, Val Loss: 55.8683\n",
      "Trial 2, Epoch [16/100] - Train Loss: 55.8986, Val Loss: 55.6600\n",
      "Trial 2, Epoch [17/100] - Train Loss: 55.6989, Val Loss: 55.4786\n",
      "Trial 2, Epoch [18/100] - Train Loss: 55.5234, Val Loss: 55.2688\n",
      "Trial 2, Epoch [19/100] - Train Loss: 55.3233, Val Loss: 55.0951\n",
      "Trial 2, Epoch [20/100] - Train Loss: 55.1563, Val Loss: 54.9251\n",
      "Trial 2, Epoch [21/100] - Train Loss: 54.9896, Val Loss: 54.7181\n",
      "Trial 2, Epoch [22/100] - Train Loss: 54.7898, Val Loss: 54.5454\n",
      "Trial 2, Epoch [23/100] - Train Loss: 54.6268, Val Loss: 54.3475\n",
      "Trial 2, Epoch [24/100] - Train Loss: 54.4387, Val Loss: 54.1214\n",
      "Trial 2, Epoch [25/100] - Train Loss: 54.2192, Val Loss: 53.8723\n",
      "Trial 2, Epoch [26/100] - Train Loss: 53.9720, Val Loss: 53.5912\n",
      "Trial 2, Epoch [27/100] - Train Loss: 53.6951, Val Loss: 53.2827\n",
      "Trial 2, Epoch [28/100] - Train Loss: 53.3897, Val Loss: 52.9817\n",
      "Trial 2, Epoch [29/100] - Train Loss: 53.0966, Val Loss: 52.6975\n",
      "Trial 2, Epoch [30/100] - Train Loss: 52.8253, Val Loss: 52.3632\n",
      "Trial 2, Epoch [31/100] - Train Loss: 52.5040, Val Loss: 52.0735\n",
      "Trial 2, Epoch [32/100] - Train Loss: 52.2205, Val Loss: 51.9046\n",
      "Trial 2, Epoch [33/100] - Train Loss: 52.0567, Val Loss: 51.9407\n",
      "Trial 2, Epoch [34/100] - Train Loss: 52.1018, Val Loss: 51.7832\n",
      "Trial 2, Epoch [35/100] - Train Loss: 51.9269, Val Loss: 51.7067\n",
      "Trial 2, Epoch [36/100] - Train Loss: 51.8257, Val Loss: 51.6713\n",
      "Trial 2, Epoch [37/100] - Train Loss: 51.7739, Val Loss: 51.6392\n",
      "Trial 2, Epoch [38/100] - Train Loss: 51.7297, Val Loss: 51.6107\n",
      "Trial 2, Epoch [39/100] - Train Loss: 51.6905, Val Loss: 51.5819\n",
      "Trial 2, Epoch [40/100] - Train Loss: 51.6541, Val Loss: 51.5478\n",
      "Trial 2, Epoch [41/100] - Train Loss: 51.6152, Val Loss: 51.5083\n",
      "Trial 2, Epoch [42/100] - Train Loss: 51.5728, Val Loss: 51.4623\n",
      "Trial 2, Epoch [43/100] - Train Loss: 51.5256, Val Loss: 51.4134\n",
      "Trial 2, Epoch [44/100] - Train Loss: 51.4769, Val Loss: 51.3654\n",
      "Trial 2, Epoch [45/100] - Train Loss: 51.4308, Val Loss: 51.3155\n",
      "Trial 2, Epoch [46/100] - Train Loss: 51.3864, Val Loss: 51.2650\n",
      "Trial 2, Epoch [47/100] - Train Loss: 51.3443, Val Loss: 51.2133\n",
      "Trial 2, Epoch [48/100] - Train Loss: 51.3032, Val Loss: 51.1657\n",
      "Trial 2, Epoch [49/100] - Train Loss: 51.2661, Val Loss: 51.1223\n",
      "Trial 2, Epoch [50/100] - Train Loss: 51.2329, Val Loss: 51.0829\n",
      "Trial 2, Epoch [51/100] - Train Loss: 51.2023, Val Loss: 51.0464\n",
      "Trial 2, Epoch [52/100] - Train Loss: 51.1729, Val Loss: 51.0122\n",
      "Trial 2, Epoch [53/100] - Train Loss: 51.1437, Val Loss: 50.9797\n",
      "Trial 2, Epoch [54/100] - Train Loss: 51.1145, Val Loss: 50.9479\n",
      "Trial 2, Epoch [55/100] - Train Loss: 51.0845, Val Loss: 50.9159\n",
      "Trial 2, Epoch [56/100] - Train Loss: 51.0528, Val Loss: 50.8838\n",
      "Trial 2, Epoch [57/100] - Train Loss: 51.0197, Val Loss: 50.8525\n",
      "Trial 2, Epoch [58/100] - Train Loss: 50.9860, Val Loss: 50.8223\n",
      "Trial 2, Epoch [59/100] - Train Loss: 50.9525, Val Loss: 50.7930\n",
      "Trial 2, Epoch [60/100] - Train Loss: 50.9191, Val Loss: 50.7646\n",
      "Trial 2, Epoch [61/100] - Train Loss: 50.8861, Val Loss: 50.7371\n",
      "Trial 2, Epoch [62/100] - Train Loss: 50.8540, Val Loss: 50.7102\n",
      "Trial 2, Epoch [63/100] - Train Loss: 50.8228, Val Loss: 50.6830\n",
      "Trial 2, Epoch [64/100] - Train Loss: 50.7921, Val Loss: 50.6548\n",
      "Trial 2, Epoch [65/100] - Train Loss: 50.7616, Val Loss: 50.6256\n",
      "Trial 2, Epoch [66/100] - Train Loss: 50.7312, Val Loss: 50.5954\n",
      "Trial 2, Epoch [67/100] - Train Loss: 50.7008, Val Loss: 50.5644\n",
      "Trial 2, Epoch [68/100] - Train Loss: 50.6702, Val Loss: 50.5327\n",
      "Trial 2, Epoch [69/100] - Train Loss: 50.6394, Val Loss: 50.5003\n",
      "Trial 2, Epoch [70/100] - Train Loss: 50.6082, Val Loss: 50.4675\n",
      "Trial 2, Epoch [71/100] - Train Loss: 50.5771, Val Loss: 50.4342\n",
      "Trial 2, Epoch [72/100] - Train Loss: 50.5460, Val Loss: 50.4006\n",
      "Trial 2, Epoch [73/100] - Train Loss: 50.5149, Val Loss: 50.3668\n",
      "Trial 2, Epoch [74/100] - Train Loss: 50.4839, Val Loss: 50.3334\n",
      "Trial 2, Epoch [75/100] - Train Loss: 50.4531, Val Loss: 50.3005\n",
      "Trial 2, Epoch [76/100] - Train Loss: 50.4224, Val Loss: 50.2683\n",
      "Trial 2, Epoch [77/100] - Train Loss: 50.3919, Val Loss: 50.2368\n",
      "Trial 2, Epoch [78/100] - Train Loss: 50.3614, Val Loss: 50.2059\n",
      "Trial 2, Epoch [79/100] - Train Loss: 50.3309, Val Loss: 50.1753\n",
      "Trial 2, Epoch [80/100] - Train Loss: 50.3005, Val Loss: 50.1449\n",
      "Trial 2, Epoch [81/100] - Train Loss: 50.2700, Val Loss: 50.1147\n",
      "Trial 2, Epoch [82/100] - Train Loss: 50.2394, Val Loss: 50.0847\n",
      "Trial 2, Epoch [83/100] - Train Loss: 50.2089, Val Loss: 50.0549\n",
      "Trial 2, Epoch [84/100] - Train Loss: 50.1783, Val Loss: 50.0252\n",
      "Trial 2, Epoch [85/100] - Train Loss: 50.1477, Val Loss: 49.9956\n",
      "Trial 2, Epoch [86/100] - Train Loss: 50.1171, Val Loss: 49.9657\n",
      "Trial 2, Epoch [87/100] - Train Loss: 50.0865, Val Loss: 49.9354\n",
      "Trial 2, Epoch [88/100] - Train Loss: 50.0557, Val Loss: 49.9045\n",
      "Trial 2, Epoch [89/100] - Train Loss: 50.0249, Val Loss: 49.8733\n",
      "Trial 2, Epoch [90/100] - Train Loss: 49.9941, Val Loss: 49.8419\n",
      "Trial 2, Epoch [91/100] - Train Loss: 49.9631, Val Loss: 49.8103\n",
      "Trial 2, Epoch [92/100] - Train Loss: 49.9321, Val Loss: 49.7788\n",
      "Trial 2, Epoch [93/100] - Train Loss: 49.9010, Val Loss: 49.7473\n",
      "Trial 2, Epoch [94/100] - Train Loss: 49.8700, Val Loss: 49.7156\n",
      "Trial 2, Epoch [95/100] - Train Loss: 49.8388, Val Loss: 49.6836\n",
      "Trial 2, Epoch [96/100] - Train Loss: 49.8074, Val Loss: 49.6517\n",
      "Trial 2, Epoch [97/100] - Train Loss: 49.7758, Val Loss: 49.6197\n",
      "Trial 2, Epoch [98/100] - Train Loss: 49.7439, Val Loss: 49.5878\n",
      "Trial 2, Epoch [99/100] - Train Loss: 49.7118, Val Loss: 49.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:12:20,815] Trial 2 finished with value: 49.52395248413086 and parameters: {'ratings_embedding_dim': 24, 'ratings_lstm_hidden_size': 8, 'ratings_lstm_num_layers': 3, 'ratings_word_size': 13, 'ratings_final_mlp_factor': 4, 'ratings_embedding_output': 13, 'user_embedding_dim': 15, 'user_embedding_output': 13, 'user_factor': 10, 'expert_factor': 6}. Best is trial 1 with value: 22.17156410217285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2, Epoch [100/100] - Train Loss: 49.6794, Val Loss: 49.5240\n",
      "Trial 3 - Model parameters: 537606\n",
      "Trial 3, Epoch [1/100] - Train Loss: 45.7100, Val Loss: 46.4749\n",
      "Trial 3, Epoch [2/100] - Train Loss: 45.5886, Val Loss: 46.3622\n",
      "Trial 3, Epoch [3/100] - Train Loss: 45.4753, Val Loss: 46.2465\n",
      "Trial 3, Epoch [4/100] - Train Loss: 45.3590, Val Loss: 46.1257\n",
      "Trial 3, Epoch [5/100] - Train Loss: 45.2374, Val Loss: 45.9979\n",
      "Trial 3, Epoch [6/100] - Train Loss: 45.1089, Val Loss: 45.8623\n",
      "Trial 3, Epoch [7/100] - Train Loss: 44.9720, Val Loss: 45.7210\n",
      "Trial 3, Epoch [8/100] - Train Loss: 44.8295, Val Loss: 45.5831\n",
      "Trial 3, Epoch [9/100] - Train Loss: 44.6919, Val Loss: 45.4202\n",
      "Trial 3, Epoch [10/100] - Train Loss: 44.5298, Val Loss: 45.2274\n",
      "Trial 3, Epoch [11/100] - Train Loss: 44.3381, Val Loss: 45.0138\n",
      "Trial 3, Epoch [12/100] - Train Loss: 44.1227, Val Loss: 44.7273\n",
      "Trial 3, Epoch [13/100] - Train Loss: 43.8314, Val Loss: 44.3798\n",
      "Trial 3, Epoch [14/100] - Train Loss: 43.4782, Val Loss: 44.0047\n",
      "Trial 3, Epoch [15/100] - Train Loss: 43.1074, Val Loss: 43.5700\n",
      "Trial 3, Epoch [16/100] - Train Loss: 42.6760, Val Loss: 42.5322\n",
      "Trial 3, Epoch [17/100] - Train Loss: 41.6499, Val Loss: 40.7266\n",
      "Trial 3, Epoch [18/100] - Train Loss: 39.8974, Val Loss: 38.4874\n",
      "Trial 3, Epoch [19/100] - Train Loss: 37.7383, Val Loss: 35.7944\n",
      "Trial 3, Epoch [20/100] - Train Loss: 35.1550, Val Loss: 32.3734\n",
      "Trial 3, Epoch [21/100] - Train Loss: 31.8610, Val Loss: 28.3036\n",
      "Trial 3, Epoch [22/100] - Train Loss: 27.9532, Val Loss: 24.4575\n",
      "Trial 3, Epoch [23/100] - Train Loss: 24.3412, Val Loss: 22.4205\n",
      "Trial 3, Epoch [24/100] - Train Loss: 22.5962, Val Loss: 22.9528\n",
      "Trial 3, Epoch [25/100] - Train Loss: 23.3889, Val Loss: 23.8491\n",
      "Trial 3, Epoch [26/100] - Train Loss: 24.3489, Val Loss: 22.9336\n",
      "Trial 3, Epoch [27/100] - Train Loss: 23.3120, Val Loss: 21.1874\n",
      "Trial 3, Epoch [28/100] - Train Loss: 21.3608, Val Loss: 19.9475\n",
      "Trial 3, Epoch [29/100] - Train Loss: 19.9087, Val Loss: 19.6178\n",
      "Trial 3, Epoch [30/100] - Train Loss: 19.4022, Val Loss: 19.8889\n",
      "Trial 3, Epoch [31/100] - Train Loss: 19.5461, Val Loss: 20.2603\n",
      "Trial 3, Epoch [32/100] - Train Loss: 19.8418, Val Loss: 20.4199\n",
      "Trial 3, Epoch [33/100] - Train Loss: 19.9641, Val Loss: 20.2827\n",
      "Trial 3, Epoch [34/100] - Train Loss: 19.8204, Val Loss: 19.8915\n",
      "Trial 3, Epoch [35/100] - Train Loss: 19.4493, Val Loss: 19.3710\n",
      "Trial 3, Epoch [36/100] - Train Loss: 18.9745, Val Loss: 18.9038\n",
      "Trial 3, Epoch [37/100] - Train Loss: 18.5777, Val Loss: 18.6908\n",
      "Trial 3, Epoch [38/100] - Train Loss: 18.4458, Val Loss: 18.7833\n",
      "Trial 3, Epoch [39/100] - Train Loss: 18.6216, Val Loss: 19.0081\n",
      "Trial 3, Epoch [40/100] - Train Loss: 18.9172, Val Loss: 19.0744\n",
      "Trial 3, Epoch [41/100] - Train Loss: 19.0307, Val Loss: 18.8953\n",
      "Trial 3, Epoch [42/100] - Train Loss: 18.8627, Val Loss: 18.6075\n",
      "Trial 3, Epoch [43/100] - Train Loss: 18.5582, Val Loss: 18.4118\n",
      "Trial 3, Epoch [44/100] - Train Loss: 18.3310, Val Loss: 18.3964\n",
      "Trial 3, Epoch [45/100] - Train Loss: 18.2824, Val Loss: 18.4957\n",
      "Trial 3, Epoch [46/100] - Train Loss: 18.3632, Val Loss: 18.5516\n",
      "Trial 3, Epoch [47/100] - Train Loss: 18.4167, Val Loss: 18.5377\n",
      "Trial 3, Epoch [48/100] - Train Loss: 18.4102, Val Loss: 18.4344\n",
      "Trial 3, Epoch [49/100] - Train Loss: 18.3293, Val Loss: 18.2684\n",
      "Trial 3, Epoch [50/100] - Train Loss: 18.2004, Val Loss: 18.0959\n",
      "Trial 3, Epoch [51/100] - Train Loss: 18.0751, Val Loss: 17.9849\n",
      "Trial 3, Epoch [52/100] - Train Loss: 18.0131, Val Loss: 17.9543\n",
      "Trial 3, Epoch [53/100] - Train Loss: 18.0293, Val Loss: 17.9737\n",
      "Trial 3, Epoch [54/100] - Train Loss: 18.0845, Val Loss: 17.9918\n",
      "Trial 3, Epoch [55/100] - Train Loss: 18.1210, Val Loss: 17.9744\n",
      "Trial 3, Epoch [56/100] - Train Loss: 18.1021, Val Loss: 17.9334\n",
      "Trial 3, Epoch [57/100] - Train Loss: 18.0405, Val Loss: 17.8988\n",
      "Trial 3, Epoch [58/100] - Train Loss: 17.9725, Val Loss: 17.8976\n",
      "Trial 3, Epoch [59/100] - Train Loss: 17.9322, Val Loss: 17.9345\n",
      "Trial 3, Epoch [60/100] - Train Loss: 17.9313, Val Loss: 17.9908\n",
      "Trial 3, Epoch [61/100] - Train Loss: 17.9555, Val Loss: 18.0397\n",
      "Trial 3, Epoch [62/100] - Train Loss: 17.9811, Val Loss: 18.0623\n",
      "Trial 3, Epoch [63/100] - Train Loss: 17.9911, Val Loss: 18.0554\n",
      "Trial 3, Epoch [64/100] - Train Loss: 17.9818, Val Loss: 18.0288\n",
      "Trial 3, Epoch [65/100] - Train Loss: 17.9612, Val Loss: 17.9972\n",
      "Trial 3, Epoch [66/100] - Train Loss: 17.9414, Val Loss: 17.9718\n",
      "Trial 3, Epoch [67/100] - Train Loss: 17.9301, Val Loss: 17.9557\n",
      "Trial 3, Epoch [68/100] - Train Loss: 17.9267, Val Loss: 17.9456\n",
      "Trial 3, Epoch [69/100] - Train Loss: 17.9251, Val Loss: 17.9383\n",
      "Trial 3, Epoch [70/100] - Train Loss: 17.9202, Val Loss: 17.9344\n",
      "Trial 3, Epoch [71/100] - Train Loss: 17.9123, Val Loss: 17.9371\n",
      "Trial 3, Epoch [72/100] - Train Loss: 17.9056, Val Loss: 17.9473\n",
      "Trial 3, Epoch [73/100] - Train Loss: 17.9036, Val Loss: 17.9619\n",
      "Trial 3, Epoch [74/100] - Train Loss: 17.9057, Val Loss: 17.9750\n",
      "Trial 3, Epoch [75/100] - Train Loss: 17.9079, Val Loss: 17.9820\n",
      "Trial 3, Epoch [76/100] - Train Loss: 17.9067, Val Loss: 17.9818\n",
      "Trial 3, Epoch [77/100] - Train Loss: 17.9017, Val Loss: 17.9769\n",
      "Trial 3, Epoch [78/100] - Train Loss: 17.8954, Val Loss: 17.9716\n",
      "Trial 3, Epoch [79/100] - Train Loss: 17.8912, Val Loss: 17.9685\n",
      "Trial 3, Epoch [80/100] - Train Loss: 17.8906, Val Loss: 17.9676\n",
      "Trial 3, Epoch [81/100] - Train Loss: 17.8921, Val Loss: 17.9671\n",
      "Trial 3, Epoch [82/100] - Train Loss: 17.8928, Val Loss: 17.9657\n",
      "Trial 3, Epoch [83/100] - Train Loss: 17.8909, Val Loss: 17.9643\n",
      "Trial 3, Epoch [84/100] - Train Loss: 17.8870, Val Loss: 17.9647\n",
      "Trial 3, Epoch [85/100] - Train Loss: 17.8835, Val Loss: 17.9677\n",
      "Trial 3, Epoch [86/100] - Train Loss: 17.8820, Val Loss: 17.9722\n",
      "Trial 3, Epoch [87/100] - Train Loss: 17.8823, Val Loss: 17.9759\n",
      "Trial 3, Epoch [88/100] - Train Loss: 17.8829, Val Loss: 17.9770\n",
      "Trial 3, Epoch [89/100] - Train Loss: 17.8821, Val Loss: 17.9752\n",
      "Trial 3, Epoch [90/100] - Train Loss: 17.8799, Val Loss: 17.9719\n",
      "Trial 3, Epoch [91/100] - Train Loss: 17.8772, Val Loss: 17.9687\n",
      "Trial 3, Epoch [92/100] - Train Loss: 17.8752, Val Loss: 17.9666\n",
      "Trial 3, Epoch [93/100] - Train Loss: 17.8744, Val Loss: 17.9655\n",
      "Trial 3, Epoch [94/100] - Train Loss: 17.8742, Val Loss: 17.9648\n",
      "Trial 3, Epoch [95/100] - Train Loss: 17.8735, Val Loss: 17.9639\n",
      "Trial 3, Epoch [96/100] - Train Loss: 17.8722, Val Loss: 17.9630\n",
      "Trial 3, Epoch [97/100] - Train Loss: 17.8704, Val Loss: 17.9621\n",
      "Trial 3, Epoch [98/100] - Train Loss: 17.8688, Val Loss: 17.9613\n",
      "Trial 3, Epoch [99/100] - Train Loss: 17.8679, Val Loss: 17.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:20:21,481] Trial 3 finished with value: 17.897613525390625 and parameters: {'ratings_embedding_dim': 20, 'ratings_lstm_hidden_size': 14, 'ratings_lstm_num_layers': 1, 'ratings_word_size': 13, 'ratings_final_mlp_factor': 12, 'ratings_embedding_output': 10, 'user_embedding_dim': 8, 'user_embedding_output': 16, 'user_factor': 3, 'expert_factor': 14}. Best is trial 3 with value: 17.897613525390625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3, Epoch [100/100] - Train Loss: 17.8675, Val Loss: 17.9577\n",
      "Trial 4 - Model parameters: 882407\n",
      "Trial 4, Epoch [1/100] - Train Loss: 49.3782, Val Loss: 49.3673\n",
      "Trial 4, Epoch [2/100] - Train Loss: 49.2814, Val Loss: 49.2829\n",
      "Trial 4, Epoch [3/100] - Train Loss: 49.1917, Val Loss: 49.2012\n",
      "Trial 4, Epoch [4/100] - Train Loss: 49.1049, Val Loss: 49.1214\n",
      "Trial 4, Epoch [5/100] - Train Loss: 49.0197, Val Loss: 49.0371\n",
      "Trial 4, Epoch [6/100] - Train Loss: 48.9299, Val Loss: 48.9480\n",
      "Trial 4, Epoch [7/100] - Train Loss: 48.8350, Val Loss: 48.8545\n",
      "Trial 4, Epoch [8/100] - Train Loss: 48.7354, Val Loss: 48.7548\n",
      "Trial 4, Epoch [9/100] - Train Loss: 48.6292, Val Loss: 48.6480\n",
      "Trial 4, Epoch [10/100] - Train Loss: 48.5157, Val Loss: 48.5380\n",
      "Trial 4, Epoch [11/100] - Train Loss: 48.3985, Val Loss: 48.4260\n",
      "Trial 4, Epoch [12/100] - Train Loss: 48.2791, Val Loss: 48.3118\n",
      "Trial 4, Epoch [13/100] - Train Loss: 48.1585, Val Loss: 48.1996\n",
      "Trial 4, Epoch [14/100] - Train Loss: 48.0398, Val Loss: 48.1066\n",
      "Trial 4, Epoch [15/100] - Train Loss: 47.9389, Val Loss: 47.9799\n",
      "Trial 4, Epoch [16/100] - Train Loss: 47.8015, Val Loss: 47.8292\n",
      "Trial 4, Epoch [17/100] - Train Loss: 47.6379, Val Loss: 47.6521\n",
      "Trial 4, Epoch [18/100] - Train Loss: 47.4462, Val Loss: 47.4745\n",
      "Trial 4, Epoch [19/100] - Train Loss: 47.2525, Val Loss: 47.2910\n",
      "Trial 4, Epoch [20/100] - Train Loss: 47.0502, Val Loss: 47.0995\n",
      "Trial 4, Epoch [21/100] - Train Loss: 46.8383, Val Loss: 46.9746\n",
      "Trial 4, Epoch [22/100] - Train Loss: 46.6942, Val Loss: 46.8500\n",
      "Trial 4, Epoch [23/100] - Train Loss: 46.5482, Val Loss: 46.7287\n",
      "Trial 4, Epoch [24/100] - Train Loss: 46.4037, Val Loss: 46.6097\n",
      "Trial 4, Epoch [25/100] - Train Loss: 46.2607, Val Loss: 46.4807\n",
      "Trial 4, Epoch [26/100] - Train Loss: 46.1083, Val Loss: 46.3513\n",
      "Trial 4, Epoch [27/100] - Train Loss: 45.9585, Val Loss: 46.2583\n",
      "Trial 4, Epoch [28/100] - Train Loss: 45.8569, Val Loss: 46.1586\n",
      "Trial 4, Epoch [29/100] - Train Loss: 45.7533, Val Loss: 46.0330\n",
      "Trial 4, Epoch [30/100] - Train Loss: 45.6246, Val Loss: 45.9538\n",
      "Trial 4, Epoch [31/100] - Train Loss: 45.5447, Val Loss: 45.8918\n",
      "Trial 4, Epoch [32/100] - Train Loss: 45.4833, Val Loss: 45.8412\n",
      "Trial 4, Epoch [33/100] - Train Loss: 45.4344, Val Loss: 45.7961\n",
      "Trial 4, Epoch [34/100] - Train Loss: 45.3919, Val Loss: 45.7531\n",
      "Trial 4, Epoch [35/100] - Train Loss: 45.3510, Val Loss: 45.7095\n",
      "Trial 4, Epoch [36/100] - Train Loss: 45.3070, Val Loss: 45.6624\n",
      "Trial 4, Epoch [37/100] - Train Loss: 45.2584, Val Loss: 45.6158\n",
      "Trial 4, Epoch [38/100] - Train Loss: 45.2085, Val Loss: 45.5691\n",
      "Trial 4, Epoch [39/100] - Train Loss: 45.1572, Val Loss: 45.5234\n",
      "Trial 4, Epoch [40/100] - Train Loss: 45.1055, Val Loss: 45.4807\n",
      "Trial 4, Epoch [41/100] - Train Loss: 45.0558, Val Loss: 45.4412\n",
      "Trial 4, Epoch [42/100] - Train Loss: 45.0085, Val Loss: 45.4019\n",
      "Trial 4, Epoch [43/100] - Train Loss: 44.9613, Val Loss: 45.3613\n",
      "Trial 4, Epoch [44/100] - Train Loss: 44.9131, Val Loss: 45.3159\n",
      "Trial 4, Epoch [45/100] - Train Loss: 44.8610, Val Loss: 45.2643\n",
      "Trial 4, Epoch [46/100] - Train Loss: 44.8037, Val Loss: 45.2078\n",
      "Trial 4, Epoch [47/100] - Train Loss: 44.7430, Val Loss: 45.1507\n",
      "Trial 4, Epoch [48/100] - Train Loss: 44.6812, Val Loss: 45.1067\n",
      "Trial 4, Epoch [49/100] - Train Loss: 44.6337, Val Loss: 45.0492\n",
      "Trial 4, Epoch [50/100] - Train Loss: 44.5744, Val Loss: 45.0045\n",
      "Trial 4, Epoch [51/100] - Train Loss: 44.5304, Val Loss: 44.9561\n",
      "Trial 4, Epoch [52/100] - Train Loss: 44.4814, Val Loss: 44.8991\n",
      "Trial 4, Epoch [53/100] - Train Loss: 44.4240, Val Loss: 44.8356\n",
      "Trial 4, Epoch [54/100] - Train Loss: 44.3583, Val Loss: 44.7668\n",
      "Trial 4, Epoch [55/100] - Train Loss: 44.2871, Val Loss: 44.6941\n",
      "Trial 4, Epoch [56/100] - Train Loss: 44.2119, Val Loss: 44.4681\n",
      "Trial 4, Epoch [57/100] - Train Loss: 43.9740, Val Loss: 44.2014\n",
      "Trial 4, Epoch [58/100] - Train Loss: 43.6904, Val Loss: 43.9390\n",
      "Trial 4, Epoch [59/100] - Train Loss: 43.4067, Val Loss: 43.8400\n",
      "Trial 4, Epoch [60/100] - Train Loss: 43.2913, Val Loss: 43.7595\n",
      "Trial 4, Epoch [61/100] - Train Loss: 43.1830, Val Loss: 43.6044\n",
      "Trial 4, Epoch [62/100] - Train Loss: 42.9996, Val Loss: 43.5502\n",
      "Trial 4, Epoch [63/100] - Train Loss: 42.9415, Val Loss: 43.4967\n",
      "Trial 4, Epoch [64/100] - Train Loss: 42.8866, Val Loss: 43.4605\n",
      "Trial 4, Epoch [65/100] - Train Loss: 42.8450, Val Loss: 43.4356\n",
      "Trial 4, Epoch [66/100] - Train Loss: 42.8169, Val Loss: 43.4269\n",
      "Trial 4, Epoch [67/100] - Train Loss: 42.8019, Val Loss: 43.4198\n",
      "Trial 4, Epoch [68/100] - Train Loss: 42.7927, Val Loss: 43.4114\n",
      "Trial 4, Epoch [69/100] - Train Loss: 42.7852, Val Loss: 43.3993\n",
      "Trial 4, Epoch [70/100] - Train Loss: 42.7773, Val Loss: 43.3843\n",
      "Trial 4, Epoch [71/100] - Train Loss: 42.7682, Val Loss: 43.3679\n",
      "Trial 4, Epoch [72/100] - Train Loss: 42.7574, Val Loss: 43.3511\n",
      "Trial 4, Epoch [73/100] - Train Loss: 42.7440, Val Loss: 43.3339\n",
      "Trial 4, Epoch [74/100] - Train Loss: 42.7278, Val Loss: 43.3176\n",
      "Trial 4, Epoch [75/100] - Train Loss: 42.7098, Val Loss: 43.3036\n",
      "Trial 4, Epoch [76/100] - Train Loss: 42.6911, Val Loss: 43.2929\n",
      "Trial 4, Epoch [77/100] - Train Loss: 42.6733, Val Loss: 43.2857\n",
      "Trial 4, Epoch [78/100] - Train Loss: 42.6574, Val Loss: 43.2814\n",
      "Trial 4, Epoch [79/100] - Train Loss: 42.6442, Val Loss: 43.2783\n",
      "Trial 4, Epoch [80/100] - Train Loss: 42.6331, Val Loss: 43.2739\n",
      "Trial 4, Epoch [81/100] - Train Loss: 42.6229, Val Loss: 43.2663\n",
      "Trial 4, Epoch [82/100] - Train Loss: 42.6123, Val Loss: 43.2548\n",
      "Trial 4, Epoch [83/100] - Train Loss: 42.6004, Val Loss: 43.2400\n",
      "Trial 4, Epoch [84/100] - Train Loss: 42.5872, Val Loss: 43.2231\n",
      "Trial 4, Epoch [85/100] - Train Loss: 42.5731, Val Loss: 43.2058\n",
      "Trial 4, Epoch [86/100] - Train Loss: 42.5588, Val Loss: 43.1896\n",
      "Trial 4, Epoch [87/100] - Train Loss: 42.5447, Val Loss: 43.1751\n",
      "Trial 4, Epoch [88/100] - Train Loss: 42.5310, Val Loss: 43.1627\n",
      "Trial 4, Epoch [89/100] - Train Loss: 42.5180, Val Loss: 43.1522\n",
      "Trial 4, Epoch [90/100] - Train Loss: 42.5054, Val Loss: 43.1432\n",
      "Trial 4, Epoch [91/100] - Train Loss: 42.4933, Val Loss: 43.1350\n",
      "Trial 4, Epoch [92/100] - Train Loss: 42.4814, Val Loss: 43.1268\n",
      "Trial 4, Epoch [93/100] - Train Loss: 42.4696, Val Loss: 43.1180\n",
      "Trial 4, Epoch [94/100] - Train Loss: 42.4576, Val Loss: 43.1082\n",
      "Trial 4, Epoch [95/100] - Train Loss: 42.4453, Val Loss: 43.0974\n",
      "Trial 4, Epoch [96/100] - Train Loss: 42.4326, Val Loss: 43.0858\n",
      "Trial 4, Epoch [97/100] - Train Loss: 42.4197, Val Loss: 43.0739\n",
      "Trial 4, Epoch [98/100] - Train Loss: 42.4069, Val Loss: 43.0621\n",
      "Trial 4, Epoch [99/100] - Train Loss: 42.3942, Val Loss: 43.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:28:41,797] Trial 4 finished with value: 43.040340423583984 and parameters: {'ratings_embedding_dim': 8, 'ratings_lstm_hidden_size': 14, 'ratings_lstm_num_layers': 15, 'ratings_word_size': 11, 'ratings_final_mlp_factor': 12, 'ratings_embedding_output': 20, 'user_embedding_dim': 9, 'user_embedding_output': 9, 'user_factor': 14, 'expert_factor': 13}. Best is trial 3 with value: 17.897613525390625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4, Epoch [100/100] - Train Loss: 42.3818, Val Loss: 43.0403\n",
      "Trial 5 - Model parameters: 681859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:28:46,812] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5, Epoch [1/100] - Train Loss: 46.1339, Val Loss: 46.5849\n",
      "Trial 6 - Model parameters: 526344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:28:51,666] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6, Epoch [1/100] - Train Loss: 53.6009, Val Loss: 53.7339\n",
      "Trial 7 - Model parameters: 1256036\n",
      "Trial 7, Epoch [1/100] - Train Loss: 44.5690, Val Loss: 44.9874\n",
      "Trial 7, Epoch [2/100] - Train Loss: 44.2959, Val Loss: 44.7088\n",
      "Trial 7, Epoch [3/100] - Train Loss: 44.0213, Val Loss: 44.3938\n",
      "Trial 7, Epoch [4/100] - Train Loss: 43.7120, Val Loss: 44.0433\n",
      "Trial 7, Epoch [5/100] - Train Loss: 43.3688, Val Loss: 43.5877\n",
      "Trial 7, Epoch [6/100] - Train Loss: 42.9248, Val Loss: 43.0617\n",
      "Trial 7, Epoch [7/100] - Train Loss: 42.4135, Val Loss: 42.4479\n",
      "Trial 7, Epoch [8/100] - Train Loss: 41.8198, Val Loss: 42.1086\n",
      "Trial 7, Epoch [9/100] - Train Loss: 41.5110, Val Loss: 41.7620\n",
      "Trial 7, Epoch [10/100] - Train Loss: 41.1897, Val Loss: 41.4404\n",
      "Trial 7, Epoch [11/100] - Train Loss: 40.8759, Val Loss: 41.3007\n",
      "Trial 7, Epoch [12/100] - Train Loss: 40.7377, Val Loss: 40.8132\n",
      "Trial 7, Epoch [13/100] - Train Loss: 40.2475, Val Loss: 40.2316\n",
      "Trial 7, Epoch [14/100] - Train Loss: 39.6568, Val Loss: 39.8454\n",
      "Trial 7, Epoch [15/100] - Train Loss: 39.2560, Val Loss: 39.4752\n",
      "Trial 7, Epoch [16/100] - Train Loss: 38.8681, Val Loss: 39.0824\n",
      "Trial 7, Epoch [17/100] - Train Loss: 38.4621, Val Loss: 38.7651\n",
      "Trial 7, Epoch [18/100] - Train Loss: 38.1401, Val Loss: 38.3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:30:26,944] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7, Epoch [19/100] - Train Loss: 37.7621, Val Loss: 37.8934\n",
      "Trial 8 - Model parameters: 1000379\n",
      "Trial 8, Epoch [1/100] - Train Loss: 35.6240, Val Loss: 36.0612\n",
      "Trial 8, Epoch [2/100] - Train Loss: 35.3090, Val Loss: 35.7774\n",
      "Trial 8, Epoch [3/100] - Train Loss: 35.0271, Val Loss: 35.5050\n",
      "Trial 8, Epoch [4/100] - Train Loss: 34.7560, Val Loss: 35.2410\n",
      "Trial 8, Epoch [5/100] - Train Loss: 34.4924, Val Loss: 34.9539\n",
      "Trial 8, Epoch [6/100] - Train Loss: 34.2050, Val Loss: 34.6150\n",
      "Trial 8, Epoch [7/100] - Train Loss: 33.8666, Val Loss: 34.2194\n",
      "Trial 8, Epoch [8/100] - Train Loss: 33.4712, Val Loss: 33.7719\n",
      "Trial 8, Epoch [9/100] - Train Loss: 33.0254, Val Loss: 33.2926\n",
      "Trial 8, Epoch [10/100] - Train Loss: 32.5463, Val Loss: 32.8217\n",
      "Trial 8, Epoch [11/100] - Train Loss: 32.0734, Val Loss: 32.3604\n",
      "Trial 8, Epoch [12/100] - Train Loss: 31.6094, Val Loss: 31.9476\n",
      "Trial 8, Epoch [13/100] - Train Loss: 31.1977, Val Loss: 31.5768\n",
      "Trial 8, Epoch [14/100] - Train Loss: 30.8268, Val Loss: 31.1277\n",
      "Trial 8, Epoch [15/100] - Train Loss: 30.3937, Val Loss: 30.6654\n",
      "Trial 8, Epoch [16/100] - Train Loss: 29.9631, Val Loss: 30.1620\n",
      "Trial 8, Epoch [17/100] - Train Loss: 29.5028, Val Loss: 29.6298\n",
      "Trial 8, Epoch [18/100] - Train Loss: 29.0367, Val Loss: 28.9768\n",
      "Trial 8, Epoch [19/100] - Train Loss: 28.4611, Val Loss: 28.2198\n",
      "Trial 8, Epoch [20/100] - Train Loss: 27.7620, Val Loss: 27.5266\n",
      "Trial 8, Epoch [21/100] - Train Loss: 27.0926, Val Loss: 26.9389\n",
      "Trial 8, Epoch [22/100] - Train Loss: 26.5141, Val Loss: 26.4219\n",
      "Trial 8, Epoch [23/100] - Train Loss: 26.0085, Val Loss: 25.9109\n",
      "Trial 8, Epoch [24/100] - Train Loss: 25.5258, Val Loss: 25.3548\n",
      "Trial 8, Epoch [25/100] - Train Loss: 25.0160, Val Loss: 24.7902\n",
      "Trial 8, Epoch [26/100] - Train Loss: 24.5105, Val Loss: 24.2785\n",
      "Trial 8, Epoch [27/100] - Train Loss: 24.0549, Val Loss: 23.7882\n",
      "Trial 8, Epoch [28/100] - Train Loss: 23.5920, Val Loss: 23.2990\n",
      "Trial 8, Epoch [29/100] - Train Loss: 23.1018, Val Loss: 22.8105\n",
      "Trial 8, Epoch [30/100] - Train Loss: 22.6024, Val Loss: 22.3047\n",
      "Trial 8, Epoch [31/100] - Train Loss: 22.0946, Val Loss: 21.7736\n",
      "Trial 8, Epoch [32/100] - Train Loss: 21.5774, Val Loss: 21.1931\n",
      "Trial 8, Epoch [33/100] - Train Loss: 21.0274, Val Loss: 20.5538\n",
      "Trial 8, Epoch [34/100] - Train Loss: 20.4275, Val Loss: 19.9248\n",
      "Trial 8, Epoch [35/100] - Train Loss: 19.8468, Val Loss: 19.3143\n",
      "Trial 8, Epoch [36/100] - Train Loss: 19.2697, Val Loss: 18.7060\n",
      "Trial 8, Epoch [37/100] - Train Loss: 18.6753, Val Loss: 18.1982\n",
      "Trial 8, Epoch [38/100] - Train Loss: 18.2023, Val Loss: 17.8261\n",
      "Trial 8, Epoch [39/100] - Train Loss: 17.8619, Val Loss: 17.6188\n",
      "Trial 8, Epoch [40/100] - Train Loss: 17.6839, Val Loss: 17.5144\n",
      "Trial 8, Epoch [41/100] - Train Loss: 17.6030, Val Loss: 17.3301\n",
      "Trial 8, Epoch [42/100] - Train Loss: 17.4294, Val Loss: 17.1031\n",
      "Trial 8, Epoch [43/100] - Train Loss: 17.1903, Val Loss: 16.8968\n",
      "Trial 8, Epoch [44/100] - Train Loss: 16.9496, Val Loss: 16.7605\n",
      "Trial 8, Epoch [45/100] - Train Loss: 16.7722, Val Loss: 16.6692\n",
      "Trial 8, Epoch [46/100] - Train Loss: 16.6539, Val Loss: 16.5916\n",
      "Trial 8, Epoch [47/100] - Train Loss: 16.5675, Val Loss: 16.5184\n",
      "Trial 8, Epoch [48/100] - Train Loss: 16.4963, Val Loss: 16.4544\n",
      "Trial 8, Epoch [49/100] - Train Loss: 16.4372, Val Loss: 16.3909\n",
      "Trial 8, Epoch [50/100] - Train Loss: 16.3699, Val Loss: 16.3480\n",
      "Trial 8, Epoch [51/100] - Train Loss: 16.3181, Val Loss: 16.3343\n",
      "Trial 8, Epoch [52/100] - Train Loss: 16.2979, Val Loss: 16.3352\n",
      "Trial 8, Epoch [53/100] - Train Loss: 16.2959, Val Loss: 16.3416\n",
      "Trial 8, Epoch [54/100] - Train Loss: 16.3022, Val Loss: 16.3501\n",
      "Trial 8, Epoch [55/100] - Train Loss: 16.3020, Val Loss: 16.3545\n",
      "Trial 8, Epoch [56/100] - Train Loss: 16.2821, Val Loss: 16.3612\n",
      "Trial 8, Epoch [57/100] - Train Loss: 16.2549, Val Loss: 16.3756\n",
      "Trial 8, Epoch [58/100] - Train Loss: 16.2383, Val Loss: 16.3954\n",
      "Trial 8, Epoch [59/100] - Train Loss: 16.2360, Val Loss: 16.4164\n",
      "Trial 8, Epoch [60/100] - Train Loss: 16.2443, Val Loss: 16.4357\n",
      "Trial 8, Epoch [61/100] - Train Loss: 16.2525, Val Loss: 16.4470\n",
      "Trial 8, Epoch [62/100] - Train Loss: 16.2500, Val Loss: 16.4496\n",
      "Trial 8, Epoch [63/100] - Train Loss: 16.2398, Val Loss: 16.4425\n",
      "Trial 8, Epoch [64/100] - Train Loss: 16.2278, Val Loss: 16.4280\n",
      "Trial 8, Epoch [65/100] - Train Loss: 16.2174, Val Loss: 16.4139\n",
      "Trial 8, Epoch [66/100] - Train Loss: 16.2106, Val Loss: 16.4032\n",
      "Trial 8, Epoch [67/100] - Train Loss: 16.2033, Val Loss: 16.3944\n",
      "Trial 8, Epoch [68/100] - Train Loss: 16.1931, Val Loss: 16.3867\n",
      "Trial 8, Epoch [69/100] - Train Loss: 16.1841, Val Loss: 16.3773\n",
      "Trial 8, Epoch [70/100] - Train Loss: 16.1770, Val Loss: 16.3672\n",
      "Trial 8, Epoch [71/100] - Train Loss: 16.1740, Val Loss: 16.3618\n",
      "Trial 8, Epoch [72/100] - Train Loss: 16.1752, Val Loss: 16.3608\n",
      "Trial 8, Epoch [73/100] - Train Loss: 16.1767, Val Loss: 16.3601\n",
      "Trial 8, Epoch [74/100] - Train Loss: 16.1766, Val Loss: 16.3550\n",
      "Trial 8, Epoch [75/100] - Train Loss: 16.1743, Val Loss: 16.3443\n",
      "Trial 8, Epoch [76/100] - Train Loss: 16.1704, Val Loss: 16.3334\n",
      "Trial 8, Epoch [77/100] - Train Loss: 16.1672, Val Loss: 16.3265\n",
      "Trial 8, Epoch [78/100] - Train Loss: 16.1658, Val Loss: 16.3248\n",
      "Trial 8, Epoch [79/100] - Train Loss: 16.1652, Val Loss: 16.3253\n",
      "Trial 8, Epoch [80/100] - Train Loss: 16.1653, Val Loss: 16.3238\n",
      "Trial 8, Epoch [81/100] - Train Loss: 16.1648, Val Loss: 16.3205\n",
      "Trial 8, Epoch [82/100] - Train Loss: 16.1635, Val Loss: 16.3183\n",
      "Trial 8, Epoch [83/100] - Train Loss: 16.1618, Val Loss: 16.3187\n",
      "Trial 8, Epoch [84/100] - Train Loss: 16.1602, Val Loss: 16.3205\n",
      "Trial 8, Epoch [85/100] - Train Loss: 16.1589, Val Loss: 16.3208\n",
      "Trial 8, Epoch [86/100] - Train Loss: 16.1575, Val Loss: 16.3185\n",
      "Trial 8, Epoch [87/100] - Train Loss: 16.1560, Val Loss: 16.3155\n",
      "Trial 8, Epoch [88/100] - Train Loss: 16.1542, Val Loss: 16.3145\n",
      "Trial 8, Epoch [89/100] - Train Loss: 16.1522, Val Loss: 16.3153\n",
      "Trial 8, Epoch [90/100] - Train Loss: 16.1505, Val Loss: 16.3160\n",
      "Trial 8, Epoch [91/100] - Train Loss: 16.1494, Val Loss: 16.3153\n",
      "Trial 8, Epoch [92/100] - Train Loss: 16.1485, Val Loss: 16.3142\n",
      "Trial 8, Epoch [93/100] - Train Loss: 16.1476, Val Loss: 16.3146\n",
      "Trial 8, Epoch [94/100] - Train Loss: 16.1466, Val Loss: 16.3164\n",
      "Trial 8, Epoch [95/100] - Train Loss: 16.1456, Val Loss: 16.3182\n",
      "Trial 8, Epoch [96/100] - Train Loss: 16.1449, Val Loss: 16.3189\n",
      "Trial 8, Epoch [97/100] - Train Loss: 16.1442, Val Loss: 16.3190\n",
      "Trial 8, Epoch [98/100] - Train Loss: 16.1435, Val Loss: 16.3201\n",
      "Trial 8, Epoch [99/100] - Train Loss: 16.1425, Val Loss: 16.3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:38:44,020] Trial 8 finished with value: 16.31423568725586 and parameters: {'ratings_embedding_dim': 22, 'ratings_lstm_hidden_size': 10, 'ratings_lstm_num_layers': 15, 'ratings_word_size': 16, 'ratings_final_mlp_factor': 11, 'ratings_embedding_output': 19, 'user_embedding_dim': 10, 'user_embedding_output': 10, 'user_factor': 11, 'expert_factor': 14}. Best is trial 8 with value: 16.31423568725586.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8, Epoch [100/100] - Train Loss: 16.1413, Val Loss: 16.3227\n",
      "Trial 9 - Model parameters: 557388\n",
      "Trial 9, Epoch [1/100] - Train Loss: 39.2338, Val Loss: 39.9765\n",
      "Trial 9, Epoch [2/100] - Train Loss: 39.0881, Val Loss: 39.8277\n",
      "Trial 9, Epoch [3/100] - Train Loss: 38.9435, Val Loss: 39.6794\n",
      "Trial 9, Epoch [4/100] - Train Loss: 38.8001, Val Loss: 39.5298\n",
      "Trial 9, Epoch [5/100] - Train Loss: 38.6552, Val Loss: 39.3787\n",
      "Trial 9, Epoch [6/100] - Train Loss: 38.5084, Val Loss: 39.2298\n",
      "Trial 9, Epoch [7/100] - Train Loss: 38.3633, Val Loss: 39.0809\n",
      "Trial 9, Epoch [8/100] - Train Loss: 38.2181, Val Loss: 38.9275\n",
      "Trial 9, Epoch [9/100] - Train Loss: 38.0687, Val Loss: 38.7677\n",
      "Trial 9, Epoch [10/100] - Train Loss: 37.9131, Val Loss: 38.5907\n",
      "Trial 9, Epoch [11/100] - Train Loss: 37.7415, Val Loss: 38.4023\n",
      "Trial 9, Epoch [12/100] - Train Loss: 37.5599, Val Loss: 38.1607\n",
      "Trial 9, Epoch [13/100] - Train Loss: 37.3260, Val Loss: 37.8886\n",
      "Trial 9, Epoch [14/100] - Train Loss: 37.0635, Val Loss: 37.5946\n",
      "Trial 9, Epoch [15/100] - Train Loss: 36.7802, Val Loss: 37.2742\n",
      "Trial 9, Epoch [16/100] - Train Loss: 36.4712, Val Loss: 36.9063\n",
      "Trial 9, Epoch [17/100] - Train Loss: 36.1178, Val Loss: 36.4719\n",
      "Trial 9, Epoch [18/100] - Train Loss: 35.7034, Val Loss: 35.9292\n",
      "Trial 9, Epoch [19/100] - Train Loss: 35.1875, Val Loss: 35.2116\n",
      "Trial 9, Epoch [20/100] - Train Loss: 34.5057, Val Loss: 34.3007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:40:25,464] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9, Epoch [21/100] - Train Loss: 33.6444, Val Loss: 33.2438\n",
      "Trial 10 - Model parameters: 735788\n",
      "Trial 10, Epoch [1/100] - Train Loss: 40.8278, Val Loss: 41.4894\n",
      "Trial 10, Epoch [2/100] - Train Loss: 40.6657, Val Loss: 41.3256\n",
      "Trial 10, Epoch [3/100] - Train Loss: 40.5058, Val Loss: 41.1634\n",
      "Trial 10, Epoch [4/100] - Train Loss: 40.3476, Val Loss: 41.0031\n",
      "Trial 10, Epoch [5/100] - Train Loss: 40.1914, Val Loss: 40.8420\n",
      "Trial 10, Epoch [6/100] - Train Loss: 40.0348, Val Loss: 40.6801\n",
      "Trial 10, Epoch [7/100] - Train Loss: 39.8774, Val Loss: 40.5162\n",
      "Trial 10, Epoch [8/100] - Train Loss: 39.7181, Val Loss: 40.3552\n",
      "Trial 10, Epoch [9/100] - Train Loss: 39.5620, Val Loss: 40.1926\n",
      "Trial 10, Epoch [10/100] - Train Loss: 39.4037, Val Loss: 40.0195\n",
      "Trial 10, Epoch [11/100] - Train Loss: 39.2360, Val Loss: 39.8390\n",
      "Trial 10, Epoch [12/100] - Train Loss: 39.0612, Val Loss: 39.6341\n",
      "Trial 10, Epoch [13/100] - Train Loss: 38.8612, Val Loss: 39.3983\n",
      "Trial 10, Epoch [14/100] - Train Loss: 38.6297, Val Loss: 39.1357\n",
      "Trial 10, Epoch [15/100] - Train Loss: 38.3718, Val Loss: 38.9108\n",
      "Trial 10, Epoch [16/100] - Train Loss: 38.1516, Val Loss: 38.6902\n",
      "Trial 10, Epoch [17/100] - Train Loss: 37.9356, Val Loss: 38.4521\n",
      "Trial 10, Epoch [18/100] - Train Loss: 37.7024, Val Loss: 38.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:42:00,494] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10, Epoch [19/100] - Train Loss: 37.4493, Val Loss: 37.8665\n",
      "Trial 11 - Model parameters: 795594\n",
      "Trial 11, Epoch [1/100] - Train Loss: 41.5714, Val Loss: 42.0270\n",
      "Trial 11, Epoch [2/100] - Train Loss: 41.4412, Val Loss: 41.9105\n",
      "Trial 11, Epoch [3/100] - Train Loss: 41.3323, Val Loss: 41.8001\n",
      "Trial 11, Epoch [4/100] - Train Loss: 41.2305, Val Loss: 41.6834\n",
      "Trial 11, Epoch [5/100] - Train Loss: 41.1227, Val Loss: 41.5566\n",
      "Trial 11, Epoch [6/100] - Train Loss: 41.0062, Val Loss: 41.4154\n",
      "Trial 11, Epoch [7/100] - Train Loss: 40.8770, Val Loss: 41.2583\n",
      "Trial 11, Epoch [8/100] - Train Loss: 40.7325, Val Loss: 41.0723\n",
      "Trial 11, Epoch [9/100] - Train Loss: 40.5638, Val Loss: 40.8703\n",
      "Trial 11, Epoch [10/100] - Train Loss: 40.3841, Val Loss: 40.6777\n",
      "Trial 11, Epoch [11/100] - Train Loss: 40.2174, Val Loss: 40.4525\n",
      "Trial 11, Epoch [12/100] - Train Loss: 40.0227, Val Loss: 40.2325\n",
      "Trial 11, Epoch [13/100] - Train Loss: 39.8307, Val Loss: 40.0163\n",
      "Trial 11, Epoch [14/100] - Train Loss: 39.6431, Val Loss: 39.8245\n",
      "Trial 11, Epoch [15/100] - Train Loss: 39.4773, Val Loss: 39.7429\n",
      "Trial 11, Epoch [16/100] - Train Loss: 39.4082, Val Loss: 39.8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:43:23,449] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11, Epoch [17/100] - Train Loss: 39.4658, Val Loss: 39.8205\n",
      "Trial 12 - Model parameters: 889576\n",
      "Trial 12, Epoch [1/100] - Train Loss: 36.2114, Val Loss: 36.4472\n",
      "Trial 12, Epoch [2/100] - Train Loss: 35.9324, Val Loss: 36.1638\n",
      "Trial 12, Epoch [3/100] - Train Loss: 35.6536, Val Loss: 35.8999\n",
      "Trial 12, Epoch [4/100] - Train Loss: 35.3943, Val Loss: 35.6381\n",
      "Trial 12, Epoch [5/100] - Train Loss: 35.1363, Val Loss: 35.3788\n",
      "Trial 12, Epoch [6/100] - Train Loss: 34.8810, Val Loss: 35.0951\n",
      "Trial 12, Epoch [7/100] - Train Loss: 34.6015, Val Loss: 34.7945\n",
      "Trial 12, Epoch [8/100] - Train Loss: 34.3052, Val Loss: 34.4723\n",
      "Trial 12, Epoch [9/100] - Train Loss: 33.9872, Val Loss: 34.1197\n",
      "Trial 12, Epoch [10/100] - Train Loss: 33.6388, Val Loss: 33.7579\n",
      "Trial 12, Epoch [11/100] - Train Loss: 33.2792, Val Loss: 33.2958\n",
      "Trial 12, Epoch [12/100] - Train Loss: 32.8200, Val Loss: 32.7989\n",
      "Trial 12, Epoch [13/100] - Train Loss: 32.3279, Val Loss: 32.2927\n",
      "Trial 12, Epoch [14/100] - Train Loss: 31.8261, Val Loss: 31.7386\n",
      "Trial 12, Epoch [15/100] - Train Loss: 31.2834, Val Loss: 31.1626\n",
      "Trial 12, Epoch [16/100] - Train Loss: 30.7142, Val Loss: 30.4816\n",
      "Trial 12, Epoch [17/100] - Train Loss: 30.0416, Val Loss: 29.6207\n",
      "Trial 12, Epoch [18/100] - Train Loss: 29.1903, Val Loss: 28.5295\n",
      "Trial 12, Epoch [19/100] - Train Loss: 28.1120, Val Loss: 27.1527\n",
      "Trial 12, Epoch [20/100] - Train Loss: 26.7618, Val Loss: 25.5907\n",
      "Trial 12, Epoch [21/100] - Train Loss: 25.2261, Val Loss: 23.8927\n",
      "Trial 12, Epoch [22/100] - Train Loss: 23.5632, Val Loss: 22.1810\n",
      "Trial 12, Epoch [23/100] - Train Loss: 21.8959, Val Loss: 20.7638\n",
      "Trial 12, Epoch [24/100] - Train Loss: 20.5439, Val Loss: 20.0208\n",
      "Trial 12, Epoch [25/100] - Train Loss: 19.9193, Val Loss: 20.3404\n",
      "Trial 12, Epoch [26/100] - Train Loss: 20.3920, Val Loss: 20.8994\n",
      "Trial 12, Epoch [27/100] - Train Loss: 21.0881, Val Loss: 20.7164\n",
      "Trial 12, Epoch [28/100] - Train Loss: 20.9751, Val Loss: 20.0883\n",
      "Trial 12, Epoch [29/100] - Train Loss: 20.3534, Val Loss: 19.6256\n",
      "Trial 12, Epoch [30/100] - Train Loss: 19.8566, Val Loss: 19.4755\n",
      "Trial 12, Epoch [31/100] - Train Loss: 19.6626, Val Loss: 19.5890\n",
      "Trial 12, Epoch [32/100] - Train Loss: 19.7171, Val Loss: 19.8128\n",
      "Trial 12, Epoch [33/100] - Train Loss: 19.8863, Val Loss: 20.0008\n",
      "Trial 12, Epoch [34/100] - Train Loss: 20.0320, Val Loss: 20.0774\n",
      "Trial 12, Epoch [35/100] - Train Loss: 20.0793, Val Loss: 20.0454\n",
      "Trial 12, Epoch [36/100] - Train Loss: 20.0287, Val Loss: 19.9403\n",
      "Trial 12, Epoch [37/100] - Train Loss: 19.9103, Val Loss: 19.7988\n",
      "Trial 12, Epoch [38/100] - Train Loss: 19.7626, Val Loss: 19.6687\n",
      "Trial 12, Epoch [39/100] - Train Loss: 19.6326, Val Loss: 19.5899\n",
      "Trial 12, Epoch [40/100] - Train Loss: 19.5596, Val Loss: 19.5735\n",
      "Trial 12, Epoch [41/100] - Train Loss: 19.5529, Val Loss: 19.5912\n",
      "Trial 12, Epoch [42/100] - Train Loss: 19.5838, Val Loss: 19.5931\n",
      "Trial 12, Epoch [43/100] - Train Loss: 19.6002, Val Loss: 19.5477\n",
      "Trial 12, Epoch [44/100] - Train Loss: 19.5688, Val Loss: 19.4690\n",
      "Trial 12, Epoch [45/100] - Train Loss: 19.5020, Val Loss: 19.3979\n",
      "Trial 12, Epoch [46/100] - Train Loss: 19.4397, Val Loss: 19.3646\n",
      "Trial 12, Epoch [47/100] - Train Loss: 19.4123, Val Loss: 19.3694\n",
      "Trial 12, Epoch [48/100] - Train Loss: 19.4211, Val Loss: 19.3926\n",
      "Trial 12, Epoch [49/100] - Train Loss: 19.4473, Val Loss: 19.4112\n",
      "Trial 12, Epoch [50/100] - Train Loss: 19.4689, Val Loss: 19.4103\n",
      "Trial 12, Epoch [51/100] - Train Loss: 19.4715, Val Loss: 19.3874\n",
      "Trial 12, Epoch [52/100] - Train Loss: 19.4531, Val Loss: 19.3510\n",
      "Trial 12, Epoch [53/100] - Train Loss: 19.4220, Val Loss: 19.3149\n",
      "Trial 12, Epoch [54/100] - Train Loss: 19.3916, Val Loss: 19.2928\n",
      "Trial 12, Epoch [55/100] - Train Loss: 19.3748, Val Loss: 19.2911\n",
      "Trial 12, Epoch [56/100] - Train Loss: 19.3768, Val Loss: 19.3060\n",
      "Trial 12, Epoch [57/100] - Train Loss: 19.3926, Val Loss: 19.3254\n",
      "Trial 12, Epoch [58/100] - Train Loss: 19.4094, Val Loss: 19.3373\n",
      "Trial 12, Epoch [59/100] - Train Loss: 19.4155, Val Loss: 19.3372\n",
      "Trial 12, Epoch [60/100] - Train Loss: 19.4071, Val Loss: 19.3295\n",
      "Trial 12, Epoch [61/100] - Train Loss: 19.3898, Val Loss: 19.3223\n",
      "Trial 12, Epoch [62/100] - Train Loss: 19.3732, Val Loss: 19.3210\n",
      "Trial 12, Epoch [63/100] - Train Loss: 19.3639, Val Loss: 19.3257\n",
      "Trial 12, Epoch [64/100] - Train Loss: 19.3629, Val Loss: 19.3325\n",
      "Trial 12, Epoch [65/100] - Train Loss: 19.3663, Val Loss: 19.3360\n",
      "Trial 12, Epoch [66/100] - Train Loss: 19.3693, Val Loss: 19.3336\n",
      "Trial 12, Epoch [67/100] - Train Loss: 19.3693, Val Loss: 19.3257\n",
      "Trial 12, Epoch [68/100] - Train Loss: 19.3660, Val Loss: 19.3153\n",
      "Trial 12, Epoch [69/100] - Train Loss: 19.3616, Val Loss: 19.3057\n",
      "Trial 12, Epoch [70/100] - Train Loss: 19.3584, Val Loss: 19.2992\n",
      "Trial 12, Epoch [71/100] - Train Loss: 19.3575, Val Loss: 19.2962\n",
      "Trial 12, Epoch [72/100] - Train Loss: 19.3583, Val Loss: 19.2953\n",
      "Trial 12, Epoch [73/100] - Train Loss: 19.3590, Val Loss: 19.2955\n",
      "Trial 12, Epoch [74/100] - Train Loss: 19.3582, Val Loss: 19.2963\n",
      "Trial 12, Epoch [75/100] - Train Loss: 19.3559, Val Loss: 19.2983\n",
      "Trial 12, Epoch [76/100] - Train Loss: 19.3533, Val Loss: 19.3017\n",
      "Trial 12, Epoch [77/100] - Train Loss: 19.3518, Val Loss: 19.3062\n",
      "Trial 12, Epoch [78/100] - Train Loss: 19.3518, Val Loss: 19.3104\n",
      "Trial 12, Epoch [79/100] - Train Loss: 19.3525, Val Loss: 19.3127\n",
      "Trial 12, Epoch [80/100] - Train Loss: 19.3529, Val Loss: 19.3121\n",
      "Trial 12, Epoch [81/100] - Train Loss: 19.3523, Val Loss: 19.3088\n",
      "Trial 12, Epoch [82/100] - Train Loss: 19.3505, Val Loss: 19.3039\n",
      "Trial 12, Epoch [83/100] - Train Loss: 19.3484, Val Loss: 19.2988\n",
      "Trial 12, Epoch [84/100] - Train Loss: 19.3468, Val Loss: 19.2944\n",
      "Trial 12, Epoch [85/100] - Train Loss: 19.3462, Val Loss: 19.2914\n",
      "Trial 12, Epoch [86/100] - Train Loss: 19.3463, Val Loss: 19.2894\n",
      "Trial 12, Epoch [87/100] - Train Loss: 19.3465, Val Loss: 19.2882\n",
      "Trial 12, Epoch [88/100] - Train Loss: 19.3461, Val Loss: 19.2877\n",
      "Trial 12, Epoch [89/100] - Train Loss: 19.3451, Val Loss: 19.2881\n",
      "Trial 12, Epoch [90/100] - Train Loss: 19.3438, Val Loss: 19.2894\n",
      "Trial 12, Epoch [91/100] - Train Loss: 19.3427, Val Loss: 19.2914\n",
      "Trial 12, Epoch [92/100] - Train Loss: 19.3421, Val Loss: 19.2935\n",
      "Trial 12, Epoch [93/100] - Train Loss: 19.3419, Val Loss: 19.2951\n",
      "Trial 12, Epoch [94/100] - Train Loss: 19.3417, Val Loss: 19.2955\n",
      "Trial 12, Epoch [95/100] - Train Loss: 19.3413, Val Loss: 19.2948\n",
      "Trial 12, Epoch [96/100] - Train Loss: 19.3406, Val Loss: 19.2933\n",
      "Trial 12, Epoch [97/100] - Train Loss: 19.3397, Val Loss: 19.2913\n",
      "Trial 12, Epoch [98/100] - Train Loss: 19.3388, Val Loss: 19.2893\n",
      "Trial 12, Epoch [99/100] - Train Loss: 19.3380, Val Loss: 19.2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:51:33,049] Trial 12 finished with value: 19.286043167114258 and parameters: {'ratings_embedding_dim': 19, 'ratings_lstm_hidden_size': 15, 'ratings_lstm_num_layers': 6, 'ratings_word_size': 14, 'ratings_final_mlp_factor': 10, 'ratings_embedding_output': 24, 'user_embedding_dim': 10, 'user_embedding_output': 16, 'user_factor': 7, 'expert_factor': 14}. Best is trial 8 with value: 16.31423568725586.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12, Epoch [100/100] - Train Loss: 19.3373, Val Loss: 19.2860\n",
      "Trial 13 - Model parameters: 688231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:51:38,245] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13, Epoch [1/100] - Train Loss: 43.1814, Val Loss: 43.9873\n",
      "Trial 14 - Model parameters: 897082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:51:43,334] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14, Epoch [1/100] - Train Loss: 47.7092, Val Loss: 47.5038\n",
      "Trial 15 - Model parameters: 623636\n",
      "Trial 15, Epoch [1/100] - Train Loss: 34.1490, Val Loss: 34.3451\n",
      "Trial 15, Epoch [2/100] - Train Loss: 33.7893, Val Loss: 34.0389\n",
      "Trial 15, Epoch [3/100] - Train Loss: 33.4769, Val Loss: 33.7510\n",
      "Trial 15, Epoch [4/100] - Train Loss: 33.1817, Val Loss: 33.5015\n",
      "Trial 15, Epoch [5/100] - Train Loss: 32.9229, Val Loss: 33.2545\n",
      "Trial 15, Epoch [6/100] - Train Loss: 32.6671, Val Loss: 33.0066\n",
      "Trial 15, Epoch [7/100] - Train Loss: 32.4098, Val Loss: 32.7741\n",
      "Trial 15, Epoch [8/100] - Train Loss: 32.1678, Val Loss: 32.5257\n",
      "Trial 15, Epoch [9/100] - Train Loss: 31.9076, Val Loss: 32.2959\n",
      "Trial 15, Epoch [10/100] - Train Loss: 31.6685, Val Loss: 32.0852\n",
      "Trial 15, Epoch [11/100] - Train Loss: 31.4495, Val Loss: 31.8956\n",
      "Trial 15, Epoch [12/100] - Train Loss: 31.2460, Val Loss: 31.7083\n",
      "Trial 15, Epoch [13/100] - Train Loss: 31.0387, Val Loss: 31.3389\n",
      "Trial 15, Epoch [14/100] - Train Loss: 30.6535, Val Loss: 30.9618\n",
      "Trial 15, Epoch [15/100] - Train Loss: 30.2571, Val Loss: 30.7095\n",
      "Trial 15, Epoch [16/100] - Train Loss: 29.9761, Val Loss: 30.4767\n",
      "Trial 15, Epoch [17/100] - Train Loss: 29.7142, Val Loss: 30.3159\n",
      "Trial 15, Epoch [18/100] - Train Loss: 29.5376, Val Loss: 30.0484\n",
      "Trial 15, Epoch [19/100] - Train Loss: 29.2659, Val Loss: 29.7145\n",
      "Trial 15, Epoch [20/100] - Train Loss: 28.9333, Val Loss: 29.3072\n",
      "Trial 15, Epoch [21/100] - Train Loss: 28.5402, Val Loss: 28.9787\n",
      "Trial 15, Epoch [22/100] - Train Loss: 28.2305, Val Loss: 28.6898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:53:34,482] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15, Epoch [23/100] - Train Loss: 27.9626, Val Loss: 28.4194\n",
      "Trial 16 - Model parameters: 689670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:53:39,978] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16, Epoch [1/100] - Train Loss: 44.1605, Val Loss: 44.9496\n",
      "Trial 17 - Model parameters: 914709\n",
      "Trial 17, Epoch [1/100] - Train Loss: 37.4223, Val Loss: 37.7684\n",
      "Trial 17, Epoch [2/100] - Train Loss: 37.3004, Val Loss: 37.6511\n",
      "Trial 17, Epoch [3/100] - Train Loss: 37.1832, Val Loss: 37.5374\n",
      "Trial 17, Epoch [4/100] - Train Loss: 37.0693, Val Loss: 37.4381\n",
      "Trial 17, Epoch [5/100] - Train Loss: 36.9693, Val Loss: 37.3436\n",
      "Trial 17, Epoch [6/100] - Train Loss: 36.8743, Val Loss: 37.2435\n",
      "Trial 17, Epoch [7/100] - Train Loss: 36.7731, Val Loss: 37.1644\n",
      "Trial 17, Epoch [8/100] - Train Loss: 36.6922, Val Loss: 37.0755\n",
      "Trial 17, Epoch [9/100] - Train Loss: 36.6002, Val Loss: 36.9715\n",
      "Trial 17, Epoch [10/100] - Train Loss: 36.4930, Val Loss: 36.8668\n",
      "Trial 17, Epoch [11/100] - Train Loss: 36.3838, Val Loss: 36.7676\n",
      "Trial 17, Epoch [12/100] - Train Loss: 36.2803, Val Loss: 36.6653\n",
      "Trial 17, Epoch [13/100] - Train Loss: 36.1777, Val Loss: 36.5457\n",
      "Trial 17, Epoch [14/100] - Train Loss: 36.0573, Val Loss: 36.4084\n",
      "Trial 17, Epoch [15/100] - Train Loss: 35.9183, Val Loss: 36.2817\n",
      "Trial 17, Epoch [16/100] - Train Loss: 35.7895, Val Loss: 36.1921\n",
      "Trial 17, Epoch [17/100] - Train Loss: 35.6891, Val Loss: 36.0962\n",
      "Trial 17, Epoch [18/100] - Train Loss: 35.5806, Val Loss: 36.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:55:13,207] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17, Epoch [19/100] - Train Loss: 35.4760, Val Loss: 35.9073\n",
      "Trial 18 - Model parameters: 833648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:55:18,393] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18, Epoch [1/100] - Train Loss: 45.2949, Val Loss: 45.3610\n",
      "Trial 19 - Model parameters: 1208709\n",
      "Trial 19, Epoch [1/100] - Train Loss: 34.0579, Val Loss: 34.6407\n",
      "Trial 19, Epoch [2/100] - Train Loss: 33.8443, Val Loss: 34.4200\n",
      "Trial 19, Epoch [3/100] - Train Loss: 33.6318, Val Loss: 34.1979\n",
      "Trial 19, Epoch [4/100] - Train Loss: 33.4178, Val Loss: 33.9732\n",
      "Trial 19, Epoch [5/100] - Train Loss: 33.2016, Val Loss: 33.7476\n",
      "Trial 19, Epoch [6/100] - Train Loss: 32.9847, Val Loss: 33.5008\n",
      "Trial 19, Epoch [7/100] - Train Loss: 32.7476, Val Loss: 33.2270\n",
      "Trial 19, Epoch [8/100] - Train Loss: 32.4847, Val Loss: 32.9561\n",
      "Trial 19, Epoch [9/100] - Train Loss: 32.2248, Val Loss: 32.6917\n",
      "Trial 19, Epoch [10/100] - Train Loss: 31.9694, Val Loss: 32.3847\n",
      "Trial 19, Epoch [11/100] - Train Loss: 31.6726, Val Loss: 32.0808\n",
      "Trial 19, Epoch [12/100] - Train Loss: 31.3797, Val Loss: 31.8339\n",
      "Trial 19, Epoch [13/100] - Train Loss: 31.1442, Val Loss: 31.5477\n",
      "Trial 19, Epoch [14/100] - Train Loss: 30.8737, Val Loss: 31.3119\n",
      "Trial 19, Epoch [15/100] - Train Loss: 30.6510, Val Loss: 31.1027\n",
      "Trial 19, Epoch [16/100] - Train Loss: 30.4543, Val Loss: 30.8065\n",
      "Trial 19, Epoch [17/100] - Train Loss: 30.1696, Val Loss: 30.4574\n",
      "Trial 19, Epoch [18/100] - Train Loss: 29.8364, Val Loss: 30.0517\n",
      "Trial 19, Epoch [19/100] - Train Loss: 29.4515, Val Loss: 29.6497\n",
      "Trial 19, Epoch [20/100] - Train Loss: 29.0791, Val Loss: 29.3045\n",
      "Trial 19, Epoch [21/100] - Train Loss: 28.7686, Val Loss: 29.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 19:57:07,741] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19, Epoch [22/100] - Train Loss: 28.5530, Val Loss: 28.7800\n",
      "Best trial:\n",
      "  Value: 16.31423568725586\n",
      "  Params: \n",
      "    ratings_embedding_dim: 22\n",
      "    ratings_lstm_hidden_size: 10\n",
      "    ratings_lstm_num_layers: 15\n",
      "    ratings_word_size: 16\n",
      "    ratings_final_mlp_factor: 11\n",
      "    ratings_embedding_output: 19\n",
      "    user_embedding_dim: 10\n",
      "    user_embedding_output: 10\n",
      "    user_factor: 11\n",
      "    expert_factor: 14\n",
      "Visualization couldn't be generated. Make sure matplotlib is installed.\n",
      "Epoch [1/100] - Train Loss: 38.4294, Val Loss: 38.8161\n",
      "Epoch [2/100] - Train Loss: 38.0001, Val Loss: 38.3945\n",
      "Epoch [3/100] - Train Loss: 37.5794, Val Loss: 37.9591\n",
      "Epoch [4/100] - Train Loss: 37.1462, Val Loss: 37.4818\n",
      "Epoch [5/100] - Train Loss: 36.6712, Val Loss: 37.0306\n",
      "Epoch [6/100] - Train Loss: 36.2212, Val Loss: 36.5421\n",
      "Epoch [7/100] - Train Loss: 35.7340, Val Loss: 35.9927\n",
      "Epoch [8/100] - Train Loss: 35.1864, Val Loss: 35.3384\n",
      "Epoch [9/100] - Train Loss: 34.5330, Val Loss: 34.5723\n",
      "Epoch [10/100] - Train Loss: 33.7682, Val Loss: 33.7399\n",
      "Epoch [11/100] - Train Loss: 32.9392, Val Loss: 32.7821\n",
      "Epoch [12/100] - Train Loss: 31.9854, Val Loss: 31.6422\n",
      "Epoch [13/100] - Train Loss: 30.8374, Val Loss: 30.3573\n",
      "Epoch [14/100] - Train Loss: 29.5437, Val Loss: 28.9288\n",
      "Epoch [15/100] - Train Loss: 28.1024, Val Loss: 27.5236\n",
      "Epoch [16/100] - Train Loss: 26.6665, Val Loss: 26.1234\n",
      "Epoch [17/100] - Train Loss: 25.2289, Val Loss: 24.6564\n",
      "Epoch [18/100] - Train Loss: 23.7351, Val Loss: 23.6278\n",
      "Epoch [19/100] - Train Loss: 22.6841, Val Loss: 23.2833\n",
      "Epoch [20/100] - Train Loss: 22.3568, Val Loss: 23.5490\n",
      "Epoch [21/100] - Train Loss: 22.7133, Val Loss: 23.6944\n",
      "Epoch [22/100] - Train Loss: 23.0101, Val Loss: 23.0750\n",
      "Epoch [23/100] - Train Loss: 22.5547, Val Loss: 22.3256\n",
      "Epoch [24/100] - Train Loss: 21.9367, Val Loss: 21.7242\n",
      "Epoch [25/100] - Train Loss: 21.4263, Val Loss: 21.3318\n",
      "Epoch [26/100] - Train Loss: 21.0905, Val Loss: 21.2993\n",
      "Epoch [27/100] - Train Loss: 21.0829, Val Loss: 21.4382\n",
      "Epoch [28/100] - Train Loss: 21.2176, Val Loss: 21.5687\n",
      "Epoch [29/100] - Train Loss: 21.3371, Val Loss: 21.6157\n",
      "Epoch [30/100] - Train Loss: 21.3718, Val Loss: 21.5626\n",
      "Epoch [31/100] - Train Loss: 21.3079, Val Loss: 21.4320\n",
      "Epoch [32/100] - Train Loss: 21.1636, Val Loss: 21.2676\n",
      "Epoch [33/100] - Train Loss: 20.9862, Val Loss: 21.1262\n",
      "Epoch [34/100] - Train Loss: 20.8316, Val Loss: 21.0349\n",
      "Epoch [35/100] - Train Loss: 20.7261, Val Loss: 21.0009\n",
      "Epoch [36/100] - Train Loss: 20.6755, Val Loss: 21.0154\n",
      "Epoch [37/100] - Train Loss: 20.6707, Val Loss: 21.0383\n",
      "Epoch [38/100] - Train Loss: 20.6705, Val Loss: 21.0443\n",
      "Epoch [39/100] - Train Loss: 20.6497, Val Loss: 21.0306\n",
      "Epoch [40/100] - Train Loss: 20.6061, Val Loss: 21.0176\n",
      "Epoch [41/100] - Train Loss: 20.5632, Val Loss: 21.0224\n",
      "Epoch [42/100] - Train Loss: 20.5394, Val Loss: 21.0429\n",
      "Epoch [43/100] - Train Loss: 20.5383, Val Loss: 21.0721\n",
      "Epoch [44/100] - Train Loss: 20.5538, Val Loss: 21.0971\n",
      "Epoch [45/100] - Train Loss: 20.5729, Val Loss: 21.1062\n",
      "Epoch [46/100] - Train Loss: 20.5834, Val Loss: 21.0939\n",
      "Epoch [47/100] - Train Loss: 20.5791, Val Loss: 21.0629\n",
      "Epoch [48/100] - Train Loss: 20.5610, Val Loss: 21.0217\n",
      "Epoch [49/100] - Train Loss: 20.5357, Val Loss: 20.9856\n",
      "Epoch [50/100] - Train Loss: 20.5147, Val Loss: 20.9602\n",
      "Epoch [51/100] - Train Loss: 20.5058, Val Loss: 20.9495\n",
      "Epoch [52/100] - Train Loss: 20.5085, Val Loss: 20.9471\n",
      "Epoch [53/100] - Train Loss: 20.5141, Val Loss: 20.9435\n",
      "Epoch [54/100] - Train Loss: 20.5127, Val Loss: 20.9353\n",
      "Epoch [55/100] - Train Loss: 20.5010, Val Loss: 20.9265\n",
      "Epoch [56/100] - Train Loss: 20.4839, Val Loss: 20.9233\n",
      "Epoch [57/100] - Train Loss: 20.4698, Val Loss: 20.9286\n",
      "Epoch [58/100] - Train Loss: 20.4640, Val Loss: 20.9402\n",
      "Epoch [59/100] - Train Loss: 20.4659, Val Loss: 20.9521\n",
      "Epoch [60/100] - Train Loss: 20.4709, Val Loss: 20.9586\n",
      "Epoch [61/100] - Train Loss: 20.4746, Val Loss: 20.9579\n",
      "Epoch [62/100] - Train Loss: 20.4747, Val Loss: 20.9510\n",
      "Epoch [63/100] - Train Loss: 20.4717, Val Loss: 20.9409\n",
      "Epoch [64/100] - Train Loss: 20.4678, Val Loss: 20.9301\n",
      "Epoch [65/100] - Train Loss: 20.4650, Val Loss: 20.9202\n",
      "Epoch [66/100] - Train Loss: 20.4638, Val Loss: 20.9115\n",
      "Epoch [67/100] - Train Loss: 20.4634, Val Loss: 20.9033\n",
      "Epoch [68/100] - Train Loss: 20.4622, Val Loss: 20.8954\n",
      "Epoch [69/100] - Train Loss: 20.4593, Val Loss: 20.8889\n",
      "Epoch [70/100] - Train Loss: 20.4552, Val Loss: 20.8852\n",
      "Epoch [71/100] - Train Loss: 20.4517, Val Loss: 20.8850\n",
      "Epoch [72/100] - Train Loss: 20.4500, Val Loss: 20.8873\n",
      "Epoch [73/100] - Train Loss: 20.4501, Val Loss: 20.8908\n",
      "Epoch [74/100] - Train Loss: 20.4509, Val Loss: 20.8936\n",
      "Epoch [75/100] - Train Loss: 20.4511, Val Loss: 20.8951\n",
      "Epoch [76/100] - Train Loss: 20.4502, Val Loss: 20.8954\n",
      "Epoch [77/100] - Train Loss: 20.4483, Val Loss: 20.8956\n",
      "Epoch [78/100] - Train Loss: 20.4464, Val Loss: 20.8966\n",
      "Epoch [79/100] - Train Loss: 20.4451, Val Loss: 20.8987\n",
      "Epoch [80/100] - Train Loss: 20.4445, Val Loss: 20.9019\n",
      "Epoch [81/100] - Train Loss: 20.4440, Val Loss: 20.9056\n",
      "Epoch [82/100] - Train Loss: 20.4431, Val Loss: 20.9099\n",
      "Epoch [83/100] - Train Loss: 20.4416, Val Loss: 20.9142\n",
      "Epoch [84/100] - Train Loss: 20.4400, Val Loss: 20.9183\n",
      "Epoch [85/100] - Train Loss: 20.4389, Val Loss: 20.9217\n",
      "Epoch [86/100] - Train Loss: 20.4381, Val Loss: 20.9239\n",
      "Epoch [87/100] - Train Loss: 20.4376, Val Loss: 20.9241\n",
      "Epoch [88/100] - Train Loss: 20.4369, Val Loss: 20.9224\n",
      "Epoch [89/100] - Train Loss: 20.4358, Val Loss: 20.9191\n",
      "Epoch [90/100] - Train Loss: 20.4345, Val Loss: 20.9152\n",
      "Epoch [91/100] - Train Loss: 20.4332, Val Loss: 20.9114\n",
      "Epoch [92/100] - Train Loss: 20.4323, Val Loss: 20.9080\n",
      "Epoch [93/100] - Train Loss: 20.4315, Val Loss: 20.9054\n",
      "Epoch [94/100] - Train Loss: 20.4308, Val Loss: 20.9034\n",
      "Epoch [95/100] - Train Loss: 20.4299, Val Loss: 20.9023\n",
      "Epoch [96/100] - Train Loss: 20.4289, Val Loss: 20.9019\n",
      "Epoch [97/100] - Train Loss: 20.4277, Val Loss: 20.9022\n",
      "Epoch [98/100] - Train Loss: 20.4266, Val Loss: 20.9030\n",
      "Epoch [99/100] - Train Loss: 20.4256, Val Loss: 20.9038\n",
      "Epoch [100/100] - Train Loss: 20.4246, Val Loss: 20.9043\n",
      "Final validation loss with best model: 20.9043\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization process\n",
    "best_model, study = run_optimization(n_trials=20)  # Adjust number of trials as needed\n",
    "\n",
    "# Optionally save the best model\n",
    "torch.save(best_model.state_dict(), 'best_recommender_model.pt')\n",
    "\n",
    "# Optionally plot optimization results\n",
    "try:\n",
    "    # Plot optimization history\n",
    "    plot_optimization_history(study)\n",
    "    plt.savefig('optimization_history.png')\n",
    "    \n",
    "    # Plot parameter importances\n",
    "    plot_param_importances(study)\n",
    "    plt.savefig('param_importances.png')\n",
    "except:\n",
    "    print(\"Visualization couldn't be generated. Make sure matplotlib is installed.\")\n",
    "\n",
    "# Final evaluation of the best model\n",
    "final_val_loss = evaluate(best_model)\n",
    "print(f\"Final validation loss with best model: {final_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
