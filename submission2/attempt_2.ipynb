{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingfeng/Desktop/venvs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import Literal\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "from utils.loader import MovieLensDataset\n",
    "from arquitecture.Recommender import Recommender_2\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 55\n",
    "BATCH = 300\n",
    "NUN_THREADS = 6\n",
    "DEVICE = \"cuda\"\n",
    "NUM_EPOCH = 100\n",
    "LEARNING_RATE = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Tensor Shape: torch.Size([300, 22, 19])\n",
      "User Data Tensor Shape: torch.Size([300, 23])\n",
      "Max index in rating tensor: 100\n",
      "Min index in rating tensor: 0\n",
      "Actual num_ratings from tensor: 22\n",
      "Actual user_data_input_dim: 23\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"train\", transpose_ratings=True, seed=SEED)\n",
    "test_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"test\", transpose_ratings=True, seed=SEED)\n",
    "val_dataset = MovieLensDataset(ml_path=\"ml-100k\", split=\"val\", transpose_ratings=True, seed=SEED)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH, shuffle=True, num_workers=NUN_THREADS)\n",
    "\n",
    "for user_data_tensor, rating_train_tensor, rating_test_tensor in train_dataloader:\n",
    "    print(\"Rating Tensor Shape:\", rating_train_tensor.size())\n",
    "    print(\"User Data Tensor Shape:\", user_data_tensor.size())\n",
    "    print(f\"Max index in rating tensor: {rating_train_tensor.max().item()}\")\n",
    "    print(f\"Min index in rating tensor: {rating_train_tensor.min().item()}\")\n",
    "    \n",
    "    # Get true num_ratings from data\n",
    "    batch_size, num_ratings_actual, rating_size = rating_train_tensor.size()\n",
    "    user_batch_size, user_data_dim = user_data_tensor.size()\n",
    "    \n",
    "    print(f\"Actual num_ratings from tensor: {num_ratings_actual}\")\n",
    "    print(f\"Actual user_data_input_dim: {user_data_dim}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    ratings_embedding_dim = trial.suggest_int('ratings_embedding_dim', 4, 32)\n",
    "    ratings_lstm_hidden_size = trial.suggest_int('ratings_lstm_hidden_size', 8, 64)\n",
    "    ratings_lstm_num_layers = trial.suggest_int('ratings_lstm_num_layers', 1, 32)\n",
    "    ratings_word_size = trial.suggest_int('ratings_word_size', 8, 32)\n",
    "    ratings_final_mlp_factor = trial.suggest_int('ratings_final_mlp_factor', 2, 16)\n",
    "    ratings_embedding_output = trial.suggest_int('ratings_embedding_output', 16, 64)\n",
    "    \n",
    "    user_embedding_dim = trial.suggest_int('user_embedding_dim', 8, 32)\n",
    "    user_embedding_output = trial.suggest_int('user_embedding_output', 8, 32)\n",
    "    user_factor = trial.suggest_int('user_factor', 2, 16)\n",
    "    \n",
    "    final_output_size = 19  # Fixed, since this depends on your target size\n",
    "    expert_factor = trial.suggest_int('expert_factor', 2, 16)\n",
    "    \n",
    "    # Create model with suggested hyperparameters\n",
    "    max_index_in_data = rating_train_tensor.max().item()\n",
    "    ratings_num_embeddings = max_index_in_data + 1  # Add 1 since indices are 0-based\n",
    "    \n",
    "    model = Recommender_2(\n",
    "        # For ratings embedder\n",
    "        ratings_num_embeddings=ratings_num_embeddings,\n",
    "        ratings_embedding_dim=ratings_embedding_dim,\n",
    "        ratings_num_ratings=num_ratings_actual,\n",
    "        ratings_lstm_hidden_size=ratings_lstm_hidden_size,\n",
    "        ratings_lstm_num_layers=ratings_lstm_num_layers,\n",
    "        ratings_word_size=ratings_word_size,\n",
    "        ratings_final_mlp_factor=ratings_final_mlp_factor,\n",
    "        ratings_embedding_output=ratings_embedding_output,\n",
    "        # For user embedder\n",
    "        user_num_embeddings=100,  # Could be optimized too if variable\n",
    "        user_embedding_dim=user_embedding_dim,\n",
    "        user_embedding_output=user_embedding_output,\n",
    "        user_data_input_dim=user_data_dim,\n",
    "        user_factor=user_factor,\n",
    "        # Output layer\n",
    "        final_output_size=final_output_size,\n",
    "        expert_factor=expert_factor\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    # Create model with hyperparameters suggested by Optuna\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Print model parameters for reference\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trial {trial.number} - Model parameters: {num_params}\")\n",
    "    \n",
    "    # Train and evaluate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # Track best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for user_data_tensor, rating_train_tensor, rating_test_tensor in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE)).to(DEVICE)\n",
    "            loss = criterion(outputs.to(DEVICE), rating_test_tensor.to(DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader.dataset)\n",
    "        \n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for user_data_tensor, rating_train_tensor, rating_test_tensor in val_dataloader:\n",
    "                outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE))\n",
    "                loss = criterion(outputs, rating_test_tensor.to(DEVICE))\n",
    "                running_val_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "        \n",
    "        print(f\"Trial {trial.number}, Epoch [{epoch+1}/{NUM_EPOCH}] - \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "        \n",
    "        # Report intermediate values to Optuna\n",
    "        trial.report(epoch_val_loss, epoch)\n",
    "        \n",
    "        # Handle pruning (early stopping if this trial isn't promising)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "def evaluate(model: Recommender_2):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        for user_data_tensor, rating_train_tensor, rating_test_tensor in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE)).to(DEVICE)        \n",
    "            loss = criterion(outputs.to(DEVICE), rating_test_tensor.to(DEVICE)) \n",
    "            \n",
    "            loss.backward()                 # Backpropagation\n",
    "            optimizer.step()                # Update model parameters\n",
    "            running_train_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_dataloader.dataset)\n",
    "\n",
    "        # --- Validation Phase ---32\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for user_data_tensor, rating_train_tensor, rating_test_tensor in val_dataloader:\n",
    "                \n",
    "                outputs = model(rating_train_tensor.to(DEVICE), user_data_tensor.to(DEVICE))        \n",
    "                loss = criterion(outputs, rating_test_tensor.to(DEVICE)) \n",
    "                \n",
    "                running_val_loss += loss.item() * rating_test_tensor.size()[1]\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_dataloader.dataset)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCH}] - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    \n",
    "    return epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(n_trials=50):\n",
    "    study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    \n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    # Create the best model\n",
    "    best_model = create_model(trial)\n",
    "    \n",
    "    return best_model, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 18:21:27,148] A new study created in memory with name: no-name-7c80d3d1-413d-41d4-a180-7f3320689ecc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 - Model parameters: 7818560\n",
      "Trial 0, Epoch [1/100] - Train Loss: 35.8992, Val Loss: 35.6079\n",
      "Trial 0, Epoch [2/100] - Train Loss: 35.1610, Val Loss: 34.9291\n",
      "Trial 0, Epoch [3/100] - Train Loss: 34.4733, Val Loss: 34.1509\n",
      "Trial 0, Epoch [4/100] - Train Loss: 33.5218, Val Loss: 32.2966\n",
      "Trial 0, Epoch [5/100] - Train Loss: 31.0952, Val Loss: 27.3284\n",
      "Trial 0, Epoch [6/100] - Train Loss: 26.7475, Val Loss: 28.1953\n",
      "Trial 0, Epoch [7/100] - Train Loss: 26.5068, Val Loss: 25.9473\n",
      "Trial 0, Epoch [8/100] - Train Loss: 26.1347, Val Loss: 27.2563\n",
      "Trial 0, Epoch [9/100] - Train Loss: 26.8553, Val Loss: 26.6076\n",
      "Trial 0, Epoch [10/100] - Train Loss: 25.9421, Val Loss: 25.5041\n",
      "Trial 0, Epoch [11/100] - Train Loss: 24.9949, Val Loss: 25.0348\n",
      "Trial 0, Epoch [12/100] - Train Loss: 24.5598, Val Loss: 24.3830\n",
      "Trial 0, Epoch [13/100] - Train Loss: 24.2384, Val Loss: 24.4079\n",
      "Trial 0, Epoch [14/100] - Train Loss: 24.3095, Val Loss: 24.2411\n",
      "Trial 0, Epoch [15/100] - Train Loss: 24.2544, Val Loss: 24.1786\n",
      "Trial 0, Epoch [16/100] - Train Loss: 24.1856, Val Loss: 24.1681\n",
      "Trial 0, Epoch [17/100] - Train Loss: 24.1209, Val Loss: 24.1892\n",
      "Trial 0, Epoch [18/100] - Train Loss: 24.0633, Val Loss: 24.2414\n",
      "Trial 0, Epoch [19/100] - Train Loss: 24.0673, Val Loss: 24.2107\n",
      "Trial 0, Epoch [20/100] - Train Loss: 24.0273, Val Loss: 24.1729\n",
      "Trial 0, Epoch [21/100] - Train Loss: 24.0157, Val Loss: 24.1158\n",
      "Trial 0, Epoch [22/100] - Train Loss: 23.9963, Val Loss: 24.0775\n",
      "Trial 0, Epoch [23/100] - Train Loss: 23.9752, Val Loss: 24.0649\n",
      "Trial 0, Epoch [24/100] - Train Loss: 23.9615, Val Loss: 24.0502\n",
      "Trial 0, Epoch [25/100] - Train Loss: 23.9340, Val Loss: 24.0448\n",
      "Trial 0, Epoch [26/100] - Train Loss: 23.9371, Val Loss: 24.0470\n",
      "Trial 0, Epoch [27/100] - Train Loss: 23.9049, Val Loss: 24.0411\n",
      "Trial 0, Epoch [28/100] - Train Loss: 23.8824, Val Loss: 24.0174\n",
      "Trial 0, Epoch [29/100] - Train Loss: 23.8713, Val Loss: 23.9804\n",
      "Trial 0, Epoch [30/100] - Train Loss: 23.8425, Val Loss: 23.9512\n",
      "Trial 0, Epoch [31/100] - Train Loss: 23.8095, Val Loss: 23.9169\n",
      "Trial 0, Epoch [32/100] - Train Loss: 23.7661, Val Loss: 23.8558\n",
      "Trial 0, Epoch [33/100] - Train Loss: 23.6909, Val Loss: 23.7537\n",
      "Trial 0, Epoch [34/100] - Train Loss: 23.5732, Val Loss: 23.7873\n",
      "Trial 0, Epoch [35/100] - Train Loss: 23.5215, Val Loss: 23.8171\n",
      "Trial 0, Epoch [36/100] - Train Loss: 23.5456, Val Loss: 23.8962\n",
      "Trial 0, Epoch [37/100] - Train Loss: 23.5237, Val Loss: 23.7822\n",
      "Trial 0, Epoch [38/100] - Train Loss: 23.4791, Val Loss: 23.7324\n",
      "Trial 0, Epoch [39/100] - Train Loss: 23.3765, Val Loss: 23.6407\n",
      "Trial 0, Epoch [40/100] - Train Loss: 23.2554, Val Loss: 23.6155\n",
      "Trial 0, Epoch [41/100] - Train Loss: 23.2143, Val Loss: 23.6008\n",
      "Trial 0, Epoch [42/100] - Train Loss: 23.1805, Val Loss: 23.6399\n",
      "Trial 0, Epoch [43/100] - Train Loss: 23.1562, Val Loss: 23.7002\n",
      "Trial 0, Epoch [44/100] - Train Loss: 23.0966, Val Loss: 23.6407\n",
      "Trial 0, Epoch [45/100] - Train Loss: 23.0529, Val Loss: 23.6345\n",
      "Trial 0, Epoch [46/100] - Train Loss: 23.0528, Val Loss: 23.6304\n",
      "Trial 0, Epoch [47/100] - Train Loss: 23.0032, Val Loss: 23.7069\n",
      "Trial 0, Epoch [48/100] - Train Loss: 22.9865, Val Loss: 23.6707\n",
      "Trial 0, Epoch [49/100] - Train Loss: 22.9490, Val Loss: 23.7248\n",
      "Trial 0, Epoch [50/100] - Train Loss: 22.9470, Val Loss: 23.6637\n",
      "Trial 0, Epoch [51/100] - Train Loss: 22.9283, Val Loss: 23.7412\n",
      "Trial 0, Epoch [52/100] - Train Loss: 22.9149, Val Loss: 23.6591\n",
      "Trial 0, Epoch [53/100] - Train Loss: 22.9300, Val Loss: 23.6599\n",
      "Trial 0, Epoch [54/100] - Train Loss: 22.8709, Val Loss: 23.5903\n",
      "Trial 0, Epoch [55/100] - Train Loss: 22.8208, Val Loss: 23.5576\n",
      "Trial 0, Epoch [56/100] - Train Loss: 22.7882, Val Loss: 23.6170\n",
      "Trial 0, Epoch [57/100] - Train Loss: 22.7795, Val Loss: 23.5661\n",
      "Trial 0, Epoch [58/100] - Train Loss: 22.7565, Val Loss: 23.6323\n",
      "Trial 0, Epoch [59/100] - Train Loss: 22.7263, Val Loss: 23.5454\n",
      "Trial 0, Epoch [60/100] - Train Loss: 22.7240, Val Loss: 23.5800\n",
      "Trial 0, Epoch [61/100] - Train Loss: 22.6923, Val Loss: 23.5455\n",
      "Trial 0, Epoch [62/100] - Train Loss: 22.6854, Val Loss: 23.5383\n",
      "Trial 0, Epoch [63/100] - Train Loss: 22.6344, Val Loss: 23.5810\n",
      "Trial 0, Epoch [64/100] - Train Loss: 22.6147, Val Loss: 23.4919\n",
      "Trial 0, Epoch [65/100] - Train Loss: 22.6192, Val Loss: 23.5632\n",
      "Trial 0, Epoch [66/100] - Train Loss: 22.5952, Val Loss: 23.4684\n",
      "Trial 0, Epoch [67/100] - Train Loss: 22.5966, Val Loss: 23.5897\n",
      "Trial 0, Epoch [68/100] - Train Loss: 22.5700, Val Loss: 23.4755\n",
      "Trial 0, Epoch [69/100] - Train Loss: 22.5638, Val Loss: 23.3564\n",
      "Trial 0, Epoch [70/100] - Train Loss: 22.4768, Val Loss: 23.3405\n",
      "Trial 0, Epoch [71/100] - Train Loss: 22.4164, Val Loss: 23.3477\n",
      "Trial 0, Epoch [72/100] - Train Loss: 22.4014, Val Loss: 23.3598\n",
      "Trial 0, Epoch [73/100] - Train Loss: 22.3756, Val Loss: 23.3390\n",
      "Trial 0, Epoch [74/100] - Train Loss: 22.3764, Val Loss: 23.4071\n",
      "Trial 0, Epoch [75/100] - Train Loss: 22.4208, Val Loss: 23.4892\n",
      "Trial 0, Epoch [76/100] - Train Loss: 22.5260, Val Loss: 23.4979\n",
      "Trial 0, Epoch [77/100] - Train Loss: 22.4651, Val Loss: 23.3939\n",
      "Trial 0, Epoch [78/100] - Train Loss: 22.3931, Val Loss: 22.3597\n",
      "Trial 0, Epoch [79/100] - Train Loss: 21.6099, Val Loss: 22.2681\n",
      "Trial 0, Epoch [80/100] - Train Loss: 21.5126, Val Loss: 22.3920\n",
      "Trial 0, Epoch [81/100] - Train Loss: 21.6183, Val Loss: 22.2665\n",
      "Trial 0, Epoch [82/100] - Train Loss: 21.5297, Val Loss: 22.3384\n",
      "Trial 0, Epoch [83/100] - Train Loss: 21.5924, Val Loss: 22.2702\n",
      "Trial 0, Epoch [84/100] - Train Loss: 21.6083, Val Loss: 22.3285\n",
      "Trial 0, Epoch [85/100] - Train Loss: 21.5085, Val Loss: 22.4146\n",
      "Trial 0, Epoch [86/100] - Train Loss: 21.4487, Val Loss: 22.2006\n",
      "Trial 0, Epoch [87/100] - Train Loss: 21.4156, Val Loss: 22.3124\n",
      "Trial 0, Epoch [88/100] - Train Loss: 21.3581, Val Loss: 22.4801\n",
      "Trial 0, Epoch [89/100] - Train Loss: 21.3383, Val Loss: 22.2935\n",
      "Trial 0, Epoch [90/100] - Train Loss: 21.3199, Val Loss: 22.3555\n",
      "Trial 0, Epoch [91/100] - Train Loss: 21.3174, Val Loss: 22.3742\n",
      "Trial 0, Epoch [92/100] - Train Loss: 21.2848, Val Loss: 22.3412\n",
      "Trial 0, Epoch [93/100] - Train Loss: 21.2632, Val Loss: 22.2632\n",
      "Trial 0, Epoch [94/100] - Train Loss: 21.2624, Val Loss: 22.3636\n",
      "Trial 0, Epoch [95/100] - Train Loss: 21.2701, Val Loss: 22.4246\n",
      "Trial 0, Epoch [96/100] - Train Loss: 21.2855, Val Loss: 22.4868\n",
      "Trial 0, Epoch [97/100] - Train Loss: 21.2365, Val Loss: 22.5786\n",
      "Trial 0, Epoch [98/100] - Train Loss: 21.3464, Val Loss: 22.4841\n",
      "Trial 0, Epoch [99/100] - Train Loss: 21.3142, Val Loss: 22.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 18:27:06,808] Trial 0 finished with value: 22.200599670410156 and parameters: {'ratings_embedding_dim': 20, 'ratings_lstm_hidden_size': 57, 'ratings_lstm_num_layers': 8, 'ratings_word_size': 17, 'ratings_final_mlp_factor': 11, 'ratings_embedding_output': 56, 'user_embedding_dim': 29, 'user_embedding_output': 14, 'user_factor': 6, 'expert_factor': 4}. Best is trial 0 with value: 22.200599670410156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0, Epoch [100/100] - Train Loss: 21.2917, Val Loss: 22.4179\n",
      "Trial 1 - Model parameters: 2453099\n",
      "Trial 1, Epoch [1/100] - Train Loss: 47.1597, Val Loss: 47.7529\n",
      "Trial 1, Epoch [2/100] - Train Loss: 46.8475, Val Loss: 47.4487\n",
      "Trial 1, Epoch [3/100] - Train Loss: 46.5474, Val Loss: 47.1533\n",
      "Trial 1, Epoch [4/100] - Train Loss: 46.2608, Val Loss: 46.8094\n",
      "Trial 1, Epoch [5/100] - Train Loss: 45.9094, Val Loss: 46.4605\n",
      "Trial 1, Epoch [6/100] - Train Loss: 45.5694, Val Loss: 46.0437\n",
      "Trial 1, Epoch [7/100] - Train Loss: 45.1097, Val Loss: 45.1995\n",
      "Trial 1, Epoch [8/100] - Train Loss: 44.1653, Val Loss: 43.6721\n",
      "Trial 1, Epoch [9/100] - Train Loss: 42.7798, Val Loss: 42.8218\n",
      "Trial 1, Epoch [10/100] - Train Loss: 42.1952, Val Loss: 41.0588\n",
      "Trial 1, Epoch [11/100] - Train Loss: 40.5785, Val Loss: 40.1956\n",
      "Trial 1, Epoch [12/100] - Train Loss: 39.8568, Val Loss: 39.6190\n",
      "Trial 1, Epoch [13/100] - Train Loss: 39.4467, Val Loss: 39.4608\n",
      "Trial 1, Epoch [14/100] - Train Loss: 39.3952, Val Loss: 39.4239\n",
      "Trial 1, Epoch [15/100] - Train Loss: 39.4162, Val Loss: 39.4470\n",
      "Trial 1, Epoch [16/100] - Train Loss: 39.3655, Val Loss: 39.3709\n",
      "Trial 1, Epoch [17/100] - Train Loss: 39.3145, Val Loss: 39.4199\n",
      "Trial 1, Epoch [18/100] - Train Loss: 39.3051, Val Loss: 39.4068\n",
      "Trial 1, Epoch [19/100] - Train Loss: 39.3109, Val Loss: 39.3801\n",
      "Trial 1, Epoch [20/100] - Train Loss: 39.2884, Val Loss: 39.3653\n",
      "Trial 1, Epoch [21/100] - Train Loss: 39.2763, Val Loss: 39.3485\n",
      "Trial 1, Epoch [22/100] - Train Loss: 39.2611, Val Loss: 39.3325\n",
      "Trial 1, Epoch [23/100] - Train Loss: 39.2610, Val Loss: 39.3316\n",
      "Trial 1, Epoch [24/100] - Train Loss: 39.2626, Val Loss: 39.3588\n",
      "Trial 1, Epoch [25/100] - Train Loss: 39.2419, Val Loss: 39.3626\n",
      "Trial 1, Epoch [26/100] - Train Loss: 39.2414, Val Loss: 39.3222\n",
      "Trial 1, Epoch [27/100] - Train Loss: 39.2329, Val Loss: 39.4064\n",
      "Trial 1, Epoch [28/100] - Train Loss: 39.2479, Val Loss: 39.3146\n",
      "Trial 1, Epoch [29/100] - Train Loss: 39.2515, Val Loss: 39.3557\n",
      "Trial 1, Epoch [30/100] - Train Loss: 39.2228, Val Loss: 39.3661\n",
      "Trial 1, Epoch [31/100] - Train Loss: 39.2147, Val Loss: 39.3178\n",
      "Trial 1, Epoch [32/100] - Train Loss: 39.2194, Val Loss: 39.3798\n",
      "Trial 1, Epoch [33/100] - Train Loss: 39.2099, Val Loss: 39.3337\n",
      "Trial 1, Epoch [34/100] - Train Loss: 39.2149, Val Loss: 39.3450\n",
      "Trial 1, Epoch [35/100] - Train Loss: 39.2044, Val Loss: 39.3948\n",
      "Trial 1, Epoch [36/100] - Train Loss: 39.1974, Val Loss: 39.3216\n",
      "Trial 1, Epoch [37/100] - Train Loss: 39.2053, Val Loss: 39.4237\n",
      "Trial 1, Epoch [38/100] - Train Loss: 39.2062, Val Loss: 39.3315\n",
      "Trial 1, Epoch [39/100] - Train Loss: 39.1856, Val Loss: 39.3485\n",
      "Trial 1, Epoch [40/100] - Train Loss: 39.1800, Val Loss: 39.3548\n",
      "Trial 1, Epoch [41/100] - Train Loss: 39.1823, Val Loss: 39.3581\n",
      "Trial 1, Epoch [42/100] - Train Loss: 39.1933, Val Loss: 39.3519\n",
      "Trial 1, Epoch [43/100] - Train Loss: 39.1680, Val Loss: 39.3873\n",
      "Trial 1, Epoch [44/100] - Train Loss: 39.1692, Val Loss: 39.3416\n",
      "Trial 1, Epoch [45/100] - Train Loss: 39.1584, Val Loss: 39.3890\n",
      "Trial 1, Epoch [46/100] - Train Loss: 39.1577, Val Loss: 39.3433\n",
      "Trial 1, Epoch [47/100] - Train Loss: 39.1518, Val Loss: 39.3559\n",
      "Trial 1, Epoch [48/100] - Train Loss: 39.1448, Val Loss: 39.3971\n",
      "Trial 1, Epoch [49/100] - Train Loss: 39.1402, Val Loss: 39.3529\n",
      "Trial 1, Epoch [50/100] - Train Loss: 39.1341, Val Loss: 39.3866\n",
      "Trial 1, Epoch [51/100] - Train Loss: 39.1298, Val Loss: 39.3784\n",
      "Trial 1, Epoch [52/100] - Train Loss: 39.1388, Val Loss: 39.3591\n",
      "Trial 1, Epoch [53/100] - Train Loss: 39.1237, Val Loss: 39.4149\n",
      "Trial 1, Epoch [54/100] - Train Loss: 39.1163, Val Loss: 39.3537\n",
      "Trial 1, Epoch [55/100] - Train Loss: 39.1289, Val Loss: 39.4691\n",
      "Trial 1, Epoch [56/100] - Train Loss: 39.1226, Val Loss: 39.3573\n",
      "Trial 1, Epoch [57/100] - Train Loss: 39.1422, Val Loss: 39.4740\n",
      "Trial 1, Epoch [58/100] - Train Loss: 39.1328, Val Loss: 39.3811\n",
      "Trial 1, Epoch [59/100] - Train Loss: 39.0930, Val Loss: 39.3813\n",
      "Trial 1, Epoch [60/100] - Train Loss: 39.0912, Val Loss: 39.4670\n",
      "Trial 1, Epoch [61/100] - Train Loss: 39.0994, Val Loss: 39.3650\n",
      "Trial 1, Epoch [62/100] - Train Loss: 39.1008, Val Loss: 39.4009\n",
      "Trial 1, Epoch [63/100] - Train Loss: 39.0807, Val Loss: 39.4444\n",
      "Trial 1, Epoch [64/100] - Train Loss: 39.0794, Val Loss: 39.3927\n",
      "Trial 1, Epoch [65/100] - Train Loss: 39.0830, Val Loss: 39.4651\n",
      "Trial 1, Epoch [66/100] - Train Loss: 39.0862, Val Loss: 39.4095\n",
      "Trial 1, Epoch [67/100] - Train Loss: 39.0676, Val Loss: 39.4263\n",
      "Trial 1, Epoch [68/100] - Train Loss: 39.0592, Val Loss: 39.4318\n",
      "Trial 1, Epoch [69/100] - Train Loss: 39.0543, Val Loss: 39.4128\n",
      "Trial 1, Epoch [70/100] - Train Loss: 39.0651, Val Loss: 39.4857\n",
      "Trial 1, Epoch [71/100] - Train Loss: 39.0602, Val Loss: 39.4385\n",
      "Trial 1, Epoch [72/100] - Train Loss: 39.0623, Val Loss: 39.4859\n",
      "Trial 1, Epoch [73/100] - Train Loss: 39.0684, Val Loss: 39.4334\n",
      "Trial 1, Epoch [74/100] - Train Loss: 39.0792, Val Loss: 39.5122\n",
      "Trial 1, Epoch [75/100] - Train Loss: 39.0704, Val Loss: 39.4853\n",
      "Trial 1, Epoch [76/100] - Train Loss: 39.0685, Val Loss: 39.4751\n",
      "Trial 1, Epoch [77/100] - Train Loss: 39.0528, Val Loss: 39.4487\n",
      "Trial 1, Epoch [78/100] - Train Loss: 39.0363, Val Loss: 39.4885\n",
      "Trial 1, Epoch [79/100] - Train Loss: 39.0480, Val Loss: 39.4585\n",
      "Trial 1, Epoch [80/100] - Train Loss: 39.0339, Val Loss: 39.4902\n",
      "Trial 1, Epoch [81/100] - Train Loss: 39.0324, Val Loss: 39.4900\n",
      "Trial 1, Epoch [82/100] - Train Loss: 39.0394, Val Loss: 39.5037\n",
      "Trial 1, Epoch [83/100] - Train Loss: 39.0340, Val Loss: 39.4860\n",
      "Trial 1, Epoch [84/100] - Train Loss: 39.0322, Val Loss: 39.4974\n",
      "Trial 1, Epoch [85/100] - Train Loss: 39.0226, Val Loss: 39.4965\n",
      "Trial 1, Epoch [86/100] - Train Loss: 39.0154, Val Loss: 39.5084\n",
      "Trial 1, Epoch [87/100] - Train Loss: 39.0169, Val Loss: 39.5151\n",
      "Trial 1, Epoch [88/100] - Train Loss: 39.0092, Val Loss: 39.5005\n",
      "Trial 1, Epoch [89/100] - Train Loss: 39.0024, Val Loss: 39.5245\n",
      "Trial 1, Epoch [90/100] - Train Loss: 38.9997, Val Loss: 39.5155\n",
      "Trial 1, Epoch [91/100] - Train Loss: 39.0031, Val Loss: 39.5835\n",
      "Trial 1, Epoch [92/100] - Train Loss: 39.0397, Val Loss: 39.5323\n",
      "Trial 1, Epoch [93/100] - Train Loss: 39.0279, Val Loss: 39.6034\n",
      "Trial 1, Epoch [94/100] - Train Loss: 39.0360, Val Loss: 39.5104\n",
      "Trial 1, Epoch [95/100] - Train Loss: 39.0269, Val Loss: 39.5603\n",
      "Trial 1, Epoch [96/100] - Train Loss: 39.0173, Val Loss: 39.5164\n",
      "Trial 1, Epoch [97/100] - Train Loss: 38.9761, Val Loss: 39.5201\n",
      "Trial 1, Epoch [98/100] - Train Loss: 38.9659, Val Loss: 39.5637\n",
      "Trial 1, Epoch [99/100] - Train Loss: 38.9803, Val Loss: 39.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 18:32:15,162] Trial 1 finished with value: 39.31455993652344 and parameters: {'ratings_embedding_dim': 5, 'ratings_lstm_hidden_size': 27, 'ratings_lstm_num_layers': 4, 'ratings_word_size': 25, 'ratings_final_mlp_factor': 13, 'ratings_embedding_output': 21, 'user_embedding_dim': 17, 'user_embedding_output': 22, 'user_factor': 13, 'expert_factor': 2}. Best is trial 0 with value: 22.200599670410156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1, Epoch [100/100] - Train Loss: 38.9822, Val Loss: 39.6392\n",
      "Trial 2 - Model parameters: 1279890\n",
      "Trial 2, Epoch [1/100] - Train Loss: 40.3700, Val Loss: 41.0211\n",
      "Trial 2, Epoch [2/100] - Train Loss: 39.9979, Val Loss: 40.7082\n",
      "Trial 2, Epoch [3/100] - Train Loss: 39.7000, Val Loss: 40.4457\n",
      "Trial 2, Epoch [4/100] - Train Loss: 39.4419, Val Loss: 40.2133\n",
      "Trial 2, Epoch [5/100] - Train Loss: 39.2185, Val Loss: 39.9972\n",
      "Trial 2, Epoch [6/100] - Train Loss: 38.9997, Val Loss: 39.7634\n",
      "Trial 2, Epoch [7/100] - Train Loss: 38.7578, Val Loss: 39.5086\n",
      "Trial 2, Epoch [8/100] - Train Loss: 38.4973, Val Loss: 39.1700\n",
      "Trial 2, Epoch [9/100] - Train Loss: 38.1274, Val Loss: 38.7723\n",
      "Trial 2, Epoch [10/100] - Train Loss: 37.7401, Val Loss: 38.1985\n",
      "Trial 2, Epoch [11/100] - Train Loss: 37.0355, Val Loss: 37.9873\n",
      "Trial 2, Epoch [12/100] - Train Loss: 36.7381, Val Loss: 38.0234\n",
      "Trial 2, Epoch [13/100] - Train Loss: 36.7288, Val Loss: 37.9940\n",
      "Trial 2, Epoch [14/100] - Train Loss: 36.7419, Val Loss: 37.9673\n",
      "Trial 2, Epoch [15/100] - Train Loss: 36.7123, Val Loss: 37.9646\n",
      "Trial 2, Epoch [16/100] - Train Loss: 36.7043, Val Loss: 37.9186\n",
      "Trial 2, Epoch [17/100] - Train Loss: 36.6938, Val Loss: 37.9231\n",
      "Trial 2, Epoch [18/100] - Train Loss: 36.6946, Val Loss: 37.9434\n",
      "Trial 2, Epoch [19/100] - Train Loss: 36.6846, Val Loss: 37.9536\n",
      "Trial 2, Epoch [20/100] - Train Loss: 36.6865, Val Loss: 37.9441\n",
      "Trial 2, Epoch [21/100] - Train Loss: 36.6817, Val Loss: 37.9312\n",
      "Trial 2, Epoch [22/100] - Train Loss: 36.6769, Val Loss: 37.9218\n",
      "Trial 2, Epoch [23/100] - Train Loss: 36.6838, Val Loss: 37.9180\n",
      "Trial 2, Epoch [24/100] - Train Loss: 36.6760, Val Loss: 37.9515\n",
      "Trial 2, Epoch [25/100] - Train Loss: 36.6809, Val Loss: 37.9236\n",
      "Trial 2, Epoch [26/100] - Train Loss: 36.6737, Val Loss: 37.9391\n",
      "Trial 2, Epoch [27/100] - Train Loss: 36.6675, Val Loss: 37.9408\n",
      "Trial 2, Epoch [28/100] - Train Loss: 36.6640, Val Loss: 37.9192\n",
      "Trial 2, Epoch [29/100] - Train Loss: 36.6640, Val Loss: 37.9155\n",
      "Trial 2, Epoch [30/100] - Train Loss: 36.6586, Val Loss: 37.9518\n",
      "Trial 2, Epoch [31/100] - Train Loss: 36.6546, Val Loss: 37.9129\n",
      "Trial 2, Epoch [32/100] - Train Loss: 36.6554, Val Loss: 37.9124\n",
      "Trial 2, Epoch [33/100] - Train Loss: 36.6401, Val Loss: 37.9435\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization process\n",
    "best_model, study = run_optimization(n_trials=20)  # Adjust number of trials as needed\n",
    "\n",
    "# Optionally save the best model\n",
    "torch.save(best_model.state_dict(), 'best_recommender_model.pt')\n",
    "\n",
    "# Optionally plot optimization results\n",
    "try:\n",
    "    # Plot optimization history\n",
    "    plot_optimization_history(study)\n",
    "    plt.savefig('optimization_history.png')\n",
    "    \n",
    "    # Plot parameter importances\n",
    "    plot_param_importances(study)\n",
    "    plt.savefig('param_importances.png')\n",
    "except:\n",
    "    print(\"Visualization couldn't be generated. Make sure matplotlib is installed.\")\n",
    "\n",
    "# Final evaluation of the best model\n",
    "final_val_loss = evaluate(best_model)\n",
    "print(f\"Final validation loss with best model: {final_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
